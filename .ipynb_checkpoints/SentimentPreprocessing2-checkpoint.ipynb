{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up HDFS and Google credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://sp-master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://10.164.0.2:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test Etienne JOB</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://10.164.0.2:7077 appName=Test Etienne JOB>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "LOCAL_IP = \"10.164.0.2\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Test Etienne JOB\") \\\n",
    "    .master(\"spark://10.164.0.2:7077\") \\\n",
    "    .config(\"spark.executor.cores\", 2) \\\n",
    "    .config(\"spark.cores.max\", 14) \\\n",
    "    .config(\"spark.executorEnv.SPARK_LOCAL_IP\", LOCAL_IP) \\\n",
    "    .getOrCreate()\n",
    "    #.config(\"spark.python.worker.memory\", \"6g\") \\\n",
    "    #.config(\"spark.executor.memory\", \"5g\") \\\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"./imdb-e9e7ce7a779d.json\"\n",
    "os.environ[\"HDFSCLI_CONFIG\"]=\"./.hdfscli.cfg\"\n",
    "os.environ[\"HADOOP_CONF_DIR\"]=\"/opt/hadoop-3.1.0/etc/hadoop\"\n",
    "sc.environment[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/MovieScope-1bf4856cc738.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "from functools import reduce\n",
    "\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import ArrayType, VectorUDT, Vectors\n",
    "\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation = \"pos\"\n",
    "collection=\"reviews\"\n",
    "urlsCollection=\"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[genre: string, entity: string, sentiment: double]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import collect_list\n",
    "\n",
    "grouped_entities_df = spark.read.parquet(\"hdfs://spark-master:8020/user/lmrd/\"+collection+\"/\"+urlsCollection+\"_\"+orientation+\"_grouped_entities2.pq\")\n",
    "grouped_entities_df.repartition(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1540580\n",
      "29\n",
      "301025\n",
      "30290\n"
     ]
    }
   ],
   "source": [
    "def binVector(x):\n",
    "        return Vectors.dense(np.histogram(x, bins=20, range=(-5, 5))[0])\n",
    "\n",
    "histo_udf = functions.udf(binVector, VectorUDT())#ArrayType(FloatType()))\n",
    "\n",
    "grouped_entities_df.registerTempTable(\"grouped_entities_df\")\n",
    "print(grouped_entities_df.count())\n",
    "\n",
    "grouped_entity_words = spark.sql(\"select genre, collect_list(ltrim(rtrim(entity))) as entities, count(entity) as entity_count from grouped_entities_df group by genre \")\n",
    "#grouped_entity_words = grouped_entities_df.select([\"genre\", \"entity\"]).groupBy(\"genre\").agg(collect_list(\"entity\").alias(\"entities\"))\n",
    "print(grouped_entity_words.count())\n",
    "\n",
    "grouped_entities_df.registerTempTable(\"grouped_entities_df\")\n",
    "grouped_entities_df2 = spark.sql(\"select genre as genre, ltrim(rtrim(entity)) as tentity, collect_list(sentiment) as sents, avg(sentiment) as avg_sent, stddev(sentiment) as std_sent from grouped_entities_df group by genre, tentity \")\n",
    "print(grouped_entities_df2.count())\n",
    "\n",
    "grouped_entities_df2.registerTempTable(\"grouped_entities_df\")\n",
    "grouped_entities_df3 = spark.sql(\"select genre, tentity as entity, sents, avg_sent, std_sent, size(sents) as num_sents from grouped_entities_df where abs(avg_sent)>0.3\")\n",
    "print(grouped_entities_df3.count())\n",
    "\n",
    "grouped_entities_df3 = grouped_entities_df3.withColumn(\"std_sent\", functions.when(functions.isnan(grouped_entities_df3.std_sent)==True, 0).otherwise(grouped_entities_df3.std_sent)).orderBy([ \"genre\", \"entity\"], ascending=False)\n",
    "\n",
    "grouped_entities_df3 = grouped_entities_df3.withColumn(\"sent_hist\", histo_udf(\"sents\"))\n",
    "\n",
    "#grouped_sentiment = grouped_entities_df3.select([\"genre\", \"avg_sent\", \"std_sent\"]).groupBy(\"genre\").agg(collect_list(\"avg_sent\").alias(\"avg_sent\"), collect_list(\"std_sent\").alias(\"std_sent\"))\n",
    "#grouped_entity_words.show()\n",
    "#grouped_sentiment.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------------+\n",
      "|      genre|     entity|         sentiment|\n",
      "+-----------+-----------+------------------+\n",
      "|    Fantasy|combination|3.4200000762939453|\n",
      "|    Romance|combination|3.4200000762939453|\n",
      "|     Action|combination|3.4200000762939453|\n",
      "|     Comedy|combination|3.4200000762939453|\n",
      "|    Romance|masterpiece| 3.419999837875366|\n",
      "|      Drama|masterpiece| 3.419999837875366|\n",
      "|     Comedy|masterpiece| 3.419999837875366|\n",
      "|Documentary|       film|3.3299999237060547|\n",
      "|    Romance|      movie| 3.239999771118164|\n",
      "|        War|      movie| 3.239999771118164|\n",
      "|     Action|       film| 3.239999771118164|\n",
      "|   Thriller|       film| 3.239999771118164|\n",
      "|     Comedy|      movie| 3.239999771118164|\n",
      "|     Horror|       film| 3.239999771118164|\n",
      "|    Fantasy|      movie| 3.239999771118164|\n",
      "|    Musical|      movie| 3.239999771118164|\n",
      "|  Adventure|      movie|2.7300000190734863|\n",
      "|      Drama|      movie|2.7300000190734863|\n",
      "|     Comedy|      movie|2.7300000190734863|\n",
      "|     Family|      movie|2.7300000190734863|\n",
      "+-----------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+--------------------+--------------------+--------------------+-------------------+---------+--------------------+\n",
      "|  genre|              entity|               sents|            avg_sent|           std_sent|num_sents|           sent_hist|\n",
      "+-------+--------------------+--------------------+--------------------+-------------------+---------+--------------------+\n",
      "|Western|           zorro one|  [0.64000004529953]|    0.64000004529953|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|          zorro film|[0.4899999797344208]|  0.4899999797344208|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|              yvonne| [1.709999918937683]|   1.709999918937683|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|       yakima canutt|[0.80999994277954...|  0.3433333138624827|0.40463972462144093|        3|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|           wyat earp|[0.33000001311302...| 0.33000001311302185|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|       writing style|  [0.64000004529953]|    0.64000004529953|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|               wrath|[-0.3600000143051...|-0.36000001430511475|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|               worry|[-0.3600000143051...|-0.36000001430511475|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|         working man|[-0.5199999809265...| -0.5199999809265137|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|           willpower|[-0.4899999797344...| -0.4899999797344208|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|      willian daniel|[0.35999998450279...| 0.35999998450279236|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|        william boyd|[-0.3600000143051...|-0.36000001430511475|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|william barrett t...|[-0.9000000357627...| -0.9000000357627869|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|        wholesomenes|[0.4899999797344208]|  0.4899999797344208|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|             whiskey|[-0.3600000143051...|-0.36000001430511475|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|         whip action|[0.36000001430511...| 0.36000001430511475|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|           westerner|[-0.809999942779541]|  -0.809999942779541|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|       wedding night|[-0.3000000119209...|-0.30000001192092896|                0.0|        1|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|            weaponry|[0.25, 0.64000004...|   0.445000022649765| 0.2757716766943584|        2|[0.0,0.0,0.0,0.0,...|\n",
      "|Western|            weakness|[-0.0100000007078...| -0.3250000230036676|0.44547730367863597|        2|[0.0,0.0,0.0,0.0,...|\n",
      "+-------+--------------------+--------------------+--------------------+-------------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+--------------------+------------+\n",
      "|      genre|            entities|entity_count|\n",
      "+-----------+--------------------+------------+\n",
      "|      Crime|[giallo, element,...|       93862|\n",
      "|    Romance|[idea, film, cred...|      134891|\n",
      "|   Thriller|[giallo, element,...|      119420|\n",
      "|  Adventure|[biopic, ned kell...|       67813|\n",
      "|         NA|[lydia reed, the ...|        1101|\n",
      "|      Drama|[idea, film, cred...|      308494|\n",
      "|        War|[agust villaronga...|       28057|\n",
      "|Documentary|[tobias schneebau...|       22679|\n",
      "| Reality-TV|[couple, island p...|        1193|\n",
      "|     Family|[fairy tale, sing...|       50334|\n",
      "|    Fantasy|[fairy tale, sing...|       67615|\n",
      "|  Game-Show|[elementary schoo...|         891|\n",
      "|      Adult|[cameron grant, d...|         376|\n",
      "|    History|[biopic, ned kell...|       25910|\n",
      "|    Mystery|[giallo, element,...|       59080|\n",
      "|    Musical|[fairy tale, sing...|       31480|\n",
      "|  Animation|[bromwell high, t...|       33235|\n",
      "|      Music|[cd, dvd, program...|       20873|\n",
      "|  Film-Noir|[jimmy davi, fred...|       12896|\n",
      "|     Horror|[giallo, element,...|       59398|\n",
      "+-----------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_entities_df.orderBy(\"sentiment\", ascending=False).show()\n",
    "grouped_entities_df3.show()\n",
    "grouped_entity_words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------+--------------------+\n",
      "|      genre|            entities|entity_count|                  tf|\n",
      "+-----------+--------------------+------------+--------------------+\n",
      "|      Crime|[giallo, element,...|       93862|(69858,[0,1,2,3,4...|\n",
      "|    Romance|[idea, film, cred...|      134891|(69858,[0,1,2,3,4...|\n",
      "|   Thriller|[giallo, element,...|      119420|(69858,[0,1,2,3,4...|\n",
      "|  Adventure|[biopic, ned kell...|       67813|(69858,[0,1,2,3,4...|\n",
      "|         NA|[lydia reed, the ...|        1101|(69858,[0,1,2,3,4...|\n",
      "|      Drama|[idea, film, cred...|      308494|(69858,[0,1,2,3,4...|\n",
      "|        War|[agust villaronga...|       28057|(69858,[0,1,2,3,4...|\n",
      "|Documentary|[tobias schneebau...|       22679|(69858,[0,1,2,3,4...|\n",
      "| Reality-TV|[couple, island p...|        1193|(69858,[1,2,3,4,5...|\n",
      "|     Family|[fairy tale, sing...|       50334|(69858,[0,1,2,3,4...|\n",
      "|    Fantasy|[fairy tale, sing...|       67615|(69858,[0,1,2,3,4...|\n",
      "|  Game-Show|[elementary schoo...|         891|(69858,[2,3,5,6,8...|\n",
      "|      Adult|[cameron grant, d...|         376|(69858,[0,1,3,4,5...|\n",
      "|    History|[biopic, ned kell...|       25910|(69858,[0,1,2,3,4...|\n",
      "|    Mystery|[giallo, element,...|       59080|(69858,[0,1,2,3,4...|\n",
      "|    Musical|[fairy tale, sing...|       31480|(69858,[0,1,2,3,4...|\n",
      "|  Animation|[bromwell high, t...|       33235|(69858,[0,1,2,3,4...|\n",
      "|      Music|[cd, dvd, program...|       20873|(69858,[0,1,2,3,4...|\n",
      "|  Film-Noir|[jimmy davi, fred...|       12896|(69858,[0,1,2,3,4...|\n",
      "|     Horror|[giallo, element,...|       59398|(69858,[0,1,2,3,4...|\n",
      "+-----------+--------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+--------------------+------------+--------------------+--------------------+\n",
      "|      genre|            entities|entity_count|                  tf|               tfidf|\n",
      "+-----------+--------------------+------------+--------------------+--------------------+\n",
      "|      Crime|[giallo, element,...|       93862|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|    Romance|[idea, film, cred...|      134891|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|   Thriller|[giallo, element,...|      119420|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|  Adventure|[biopic, ned kell...|       67813|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|         NA|[lydia reed, the ...|        1101|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|      Drama|[idea, film, cred...|      308494|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|        War|[agust villaronga...|       28057|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|Documentary|[tobias schneebau...|       22679|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "| Reality-TV|[couple, island p...|        1193|(69858,[1,2,3,4,5...|(69858,[1,2,3,4,5...|\n",
      "|     Family|[fairy tale, sing...|       50334|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|    Fantasy|[fairy tale, sing...|       67615|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|  Game-Show|[elementary schoo...|         891|(69858,[2,3,5,6,8...|(69858,[2,3,5,6,8...|\n",
      "|      Adult|[cameron grant, d...|         376|(69858,[0,1,3,4,5...|(69858,[0,1,3,4,5...|\n",
      "|    History|[biopic, ned kell...|       25910|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|    Mystery|[giallo, element,...|       59080|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|    Musical|[fairy tale, sing...|       31480|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|  Animation|[bromwell high, t...|       33235|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|      Music|[cd, dvd, program...|       20873|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|  Film-Noir|[jimmy davi, fred...|       12896|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "|     Horror|[giallo, element,...|       59398|(69858,[0,1,2,3,4...|(69858,[0,1,2,3,4...|\n",
      "+-----------+--------------------+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "\n",
    "# remove sentiment info for use by hashingTF/tfif\n",
    "\n",
    "# Load documents (one per line).\n",
    "\n",
    "countVec = CountVectorizer(inputCol=\"entities\", outputCol=\"tf\")\n",
    "cvmodel = countVec.fit(grouped_entity_words)\n",
    "\n",
    "tf = cvmodel.transform(grouped_entity_words)\n",
    "tf.show()\n",
    "#sc.broadcast(hashingTF)\n",
    "\n",
    "# While applying HashingTF only needs a single pass to the data, applying IDF needs two passes:\n",
    "# First to compute the IDF vector and second to scale the term frequencies by IDF.\n",
    "tf.cache()\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tfidf\").fit(tf)\n",
    "tfidf = idf.transform(tf)\n",
    "tfidf.show()\n",
    "# spark.mllib's IDF implementation provides an option for ignoring terms\n",
    "# which occur in less than a minimum number of documents.\n",
    "# In such cases, the IDF for these terms is set to 0.\n",
    "# This feature can be used by passing the minDocFreq value to the IDF constructor.\n",
    "# idfIgnore = IDF(minDocFreq=2).fit(tf)\n",
    "# tfidfIgnore = idfIgnore.transform(tf)\n",
    "\n",
    "tfidf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+------------------+----------+--------------------+--------------------+-------------------+---------+--------------------+\n",
      "|  genre|          entity|             tfidf|vocabIndex|               sents|            avg_sent|           std_sent|num_sents|           sent_hist|\n",
      "+-------+----------------+------------------+----------+--------------------+--------------------+-------------------+---------+--------------------+\n",
      "|Fantasy|        malfique|16.119224164338117|      6191|[1.36000001430511...| 0.40500001329928637|  0.594906973451176|        8|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|           marcu|14.552872326068421|      5032|[0.0, -1.10000002...| -0.4340000103227794| 0.4941479835549382|       10|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|        lassalle|14.104321143795852|      6989|[-0.0100000007078...| -0.3128571461087891|0.32780655646770873|        7|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|           beast|12.332476867384303|      1091|[-2.0799999237060...|-0.33370370066000354|0.43040362695333745|       27|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|   taylor momsen|12.089418123253587|      8041|[0.45000001788139...| 0.30166666380440194|0.41208816212526633|        6|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|         gillian|12.089418123253587|      7912|[0.0, 0.359999984...|  0.4916666713543236| 1.0939546200065888|        6|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|  luke skywalker| 12.03972804325936|      3775|[0.01000000070780...|-0.35299999909475444| 0.6300096887226415|       10|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|       annemarie|10.187010628247894|      3859|[0.0, 0.0, 0.0, -...| -0.3285714329353401| 0.5791496357366264|        7|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|character design| 9.010913347279288|      2243|[0.80999994277954...|  0.3315384522653543| 0.3385224121881414|       13|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|        dinosaur| 8.800521231913237|      1591|[-0.0400000028312...| 0.30928570524390253| 0.4961926240759666|       14|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|        werewolf| 8.731723395641051|      2698|[-1.0499999523162...| -0.3683333182707429| 0.5290147824608349|        6|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|           shame| 8.256311398625762|       355|[-0.9799999594688...|-0.41702702586111184|0.36866774438876276|       37|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|          visual| 8.256311398625762|       426|[0.0, 0.489999979...|  0.3113513389300253|0.41138086385111744|       37|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|       nightmare| 7.443718279292147|       595|[-0.4899999797344...| -0.4412499925044055| 0.3808150381139507|       24|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|         valerie|7.2764361630342105|      6149|[0.80999994277954...|  0.5300000071525574| 0.5246903948564873|        5|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|       the beast|  7.16703787691222|      8812|[-0.1000000014901...| -0.6800000090152025| 1.0290448888894879|        4|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|    paul wegener|  7.16703787691222|      8567|[1.70999991893768...|  0.4274999797344208| 0.8549999594688416|        4|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|  jabba the hutt|  7.16703787691222|      8624|[-0.3000000119209...|-0.40750001557171345| 0.4567548766433714|        4|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|           muska|  7.16703787691222|      8495|[-0.8099999427795...| -0.3074999824166298| 0.3891336272383438|        4|[0.0,0.0,0.0,0.0,...|\n",
      "|Fantasy|         serpent| 6.608779199911598|      6412|[-1.7099999189376...| -0.5059999724850058| 0.7583072875341772|        5|[0.0,0.0,0.0,0.0,...|\n",
      "+-------+----------------+------------------+----------+--------------------+--------------------+-------------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1323\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import explode\n",
    "import numpy as np\n",
    "\n",
    "tfidf = tfidf.repartition(100)\n",
    "vocab = tfidf.select([\"genre\", \"tfidf\"])\n",
    "genreVocabs = dict()\n",
    "\n",
    "for genre in vocab.collect():\n",
    "    genreName = genre.genre\n",
    "    \n",
    "    t=genre.tfidf\n",
    "    genreVocabs[genreName] = t\n",
    "    \n",
    "globalVocab = list(cvmodel.vocabulary)\n",
    "#print(genreVocabs)\n",
    "    \n",
    "sc.broadcast(globalVocab)\n",
    "sc.broadcast(genreVocabs)\n",
    "\n",
    "def remapEntitiesByTfidf(row):\n",
    "    tfidfMappings = genreVocabs[row.genre]\n",
    "    tfIndex = globalVocab.index(row.entity)\n",
    "    tfidf = tfidfMappings[tfIndex]\n",
    "    \n",
    "    return Row(genre=row.genre, entity=row.entity, tfidf=float(tfidf), vocabIndex=int(tfIndex))\n",
    "    \n",
    "genreCorpora=dict()\n",
    "\n",
    "for genre in genreVocabs.keys():\n",
    "\n",
    "    genreEntities = tfidf.where(tfidf.genre==genre).select(\"genre\", explode(\"entities\").alias(\"entity\")).distinct()\n",
    "    \n",
    "    print(genreEntities.count())\n",
    "    #genreEntities.orderBy([\"genre\", \"entity\"]).show()\n",
    "    \n",
    "    #data = genreEntities.rdd.map(remapEntitiesByTfidf)\n",
    "\n",
    "    entitiesByTfidf = spark.createDataFrame(data=genreEntities.rdd.map(remapEntitiesByTfidf), schema=[\"entity\", \"genre\", \"tfidf\", \"vocabIndex\"])\n",
    "    print(entitiesByTfidf())\n",
    "    #entitiesByTfidf.orderBy([\"genre\", \"entity\"]).show()\n",
    "    entitiesByTfidf = entitiesByTfidf.join(grouped_entities_df3, on=[\"genre\", \"entity\"], how=\"inner\")#.sort(\"tfidf\", ascending=False)\n",
    "    entitiesByTfidf.orderBy(\"tfidf\", ascending=False).show()\n",
    "    genreCorpora[genre] = entitiesByTfidf\n",
    "    \n",
    "    print(entitiesByTfidf.count())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fantasy\n",
      "Game-Show\n",
      "Talk-Show\n",
      "Adventure\n",
      "Horror\n",
      "Short\n",
      "Drama\n",
      "Romance\n",
      "Thriller\n",
      "War\n",
      "Musical\n",
      "Music\n",
      "Western\n",
      "History\n",
      "Documentary\n",
      "Comedy\n",
      "Family\n",
      "Sci-Fi\n",
      "NA\n",
      "News\n",
      "Animation\n",
      "Biography\n",
      "Adult\n",
      "Crime\n",
      "Mystery\n",
      "Film-Noir\n",
      "Action\n",
      "Sport\n",
      "Reality-TV\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "for (genreName, corpus) in genreCorpora.items():\n",
    "    print(genreName)\n",
    "    df = corpus.select(col(\"genre\"), col(\"entity\"), col(\"tfidf\"), col(\"vocabIndex\"), col(\"avg_sent\"), col(\"std_sent\"), col(\"sent_hist\"))\n",
    "\n",
    "    df.write.parquet(\"hdfs://spark-master:8020/user/lmrd/\"+collection+\"/\"+genreName+\"_\"+orientation+\"_tfidf3.pq\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "crime_df = spark.read.parquet(\"hdfs://spark-master:8020/user/lmrd/Crime_neg_tfidf2.pq\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "crime_df.show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "crime_df.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "crime_df.orderBy(\"tfidf\", ascending=False).show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
