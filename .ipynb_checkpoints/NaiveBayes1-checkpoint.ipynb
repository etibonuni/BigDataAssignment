{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up HDFS and Google credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://sp-master:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://sp-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://sp-master:7077 appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"./imdb-e9e7ce7a779d.json\"\n",
    "os.environ[\"HDFSCLI_CONFIG\"]=\"./.hdfscli.cfg\"\n",
    "os.environ[\"HADOOP_CONF_DIR\"]=\"/opt/hadoop-3.1.0/etc/hadoop\"\n",
    "sc.environment[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/MovieScope-1bf4856cc738.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List filenames of reviews from HDFS and parallelize in preparation from processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelise the reviews and use Google NLP API to extract entities and related sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window as W\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as functions\n",
    "from pyspark.sql.functions import collect_list\n",
    "from pyspark.sql.functions import collect_set\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "#from pyspark.mllib.linalg import SparseVector, DenseVector, VectorUDT\n",
    "from pyspark.ml.linalg import SparseVector, DenseVector, VectorUDT\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel, RandomForestClassifier, RandomForestClassificationModel\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel, HashingTF, IDF, IDFModel, StringIndexer, StringIndexerModel, IndexToString\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from functools import reduce\n",
    "import re\n",
    "import numpy as np\n",
    "from math import exp\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import base64\n",
    "\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectEntities(x, y):\n",
    "    # The first reduce call doesn't pass a list for x, so we need to check for that.\n",
    "    if not isinstance(x, list):\n",
    "        x=[x]\n",
    "        \n",
    "\n",
    "    xd = dict(x)\n",
    "    #print(xd)\n",
    "    \n",
    "    if not isinstance(y, list):\n",
    "        y = [y]\n",
    "        \n",
    "    for ye in y:\n",
    "        if ye[0] in xd:\n",
    "            try:\n",
    "                xd[ye[0]] = (xd[ye[0]]+ye[1])/2\n",
    "            except:\n",
    "                Null\n",
    "        else:\n",
    "            xd[ye[0]] = ye[1]\n",
    "    \n",
    "    return [o for o in xd.items()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation = \"pos\"\n",
    "collection=\"reviews\"\n",
    "urlsCollection=\"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load genre information from file (previously collected using IMDB API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def decodeGenre(x):\n",
    "    try: \n",
    "        g = pickle.loads(base64.b64decode(x[2:-1]), encoding=\"bytes\") \n",
    "        if (len(g)==0):\n",
    "            return [\"NA\"]\n",
    "        else:\n",
    "            return g\n",
    "    except:\n",
    "        return [\"NA\"]    \n",
    "        \n",
    "\n",
    "def loadGenres(urlsCollection, orientation):\n",
    "    genres = pd.read_csv(\"Data/genres_\"+urlsCollection+\"_urls_\"+orientation+\".csv\", sep=\"\\t\", index_col=0, usecols=[1, 2, 3])\n",
    "    genres = genres.fillna(value=\"b''\")\n",
    "    genres[\"GENRE\"] = genres[\"GENRE\"].apply(decodeGenre) \n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"FILM_ID\", IntegerType(), True),\n",
    "        StructField(\"GENRE\", ArrayType(StringType(), containsNull=True), True)])\n",
    "\n",
    "    genres_df = spark.createDataFrame(genres, schema)\n",
    "\n",
    "    from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "    # This will return a new DF with all the columns + id\n",
    "    genres_df = genres_df.withColumn(\"ID_TEMP\", monotonically_increasing_id())#.limit(10)\n",
    "\n",
    "    genres_df = genres_df.withColumn(\"ID\",F.row_number().over(W.orderBy(\"ID_TEMP\"))).select([\"FILM_ID\", \"GENRE\", \"ID\"])#.limit(10)\n",
    "    \n",
    "    return genres_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emtity_documents_info\n",
      "+-----+--------------------+\n",
      "|   ID|    ENTITY_SENTIMENT|\n",
      "+-----+--------------------+\n",
      "|10037|[[titanic, -1.800...|\n",
      "|10038|[[rose, 0.0], [ja...|\n",
      "|10039|[[titanic, 0.0], ...|\n",
      "|10040|[[titanic, 1.88],...|\n",
      "| 1004|[[masterpiece, 0....|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "genres_df\n",
      "+-------+-------------------+---+\n",
      "|FILM_ID|              GENRE| ID|\n",
      "+-------+-------------------+---+\n",
      "| 453418|[Animation, Comedy]|  1|\n",
      "| 453418|[Animation, Comedy]|  2|\n",
      "| 453418|[Animation, Comedy]|  3|\n",
      "|  64354|           [Comedy]|  4|\n",
      "|  64354|           [Comedy]|  5|\n",
      "+-------+-------------------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "entity_documents_info\n",
      "+---+--------------------+-------+-------------------+---+\n",
      "| ID|    ENTITY_SENTIMENT|FILM_ID|              GENRE| ID|\n",
      "+---+--------------------+-------+-------------------+---+\n",
      "|  1|[[bromwell high, ...| 453418|[Animation, Comedy]|  1|\n",
      "|  2|[[format, 0.0], [...| 453418|[Animation, Comedy]|  2|\n",
      "|  3|[[bromwell high, ...| 453418|[Animation, Comedy]|  3|\n",
      "|  4|[[world, 0.0], [s...|  64354|           [Comedy]|  4|\n",
      "|  5|[[futz, 0.0], [pi...|  64354|           [Comedy]|  5|\n",
      "+---+--------------------+-------+-------------------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "grouped_entities\n",
      "[['Animation', 'bromwell high', 0.0], ['Comedy', 'bromwell high', 0.0], ['Animation', 'teacher', 0.0], ['Comedy', 'teacher', 0.0], ['Animation', 'program', 0.0]]\n",
      "grouped_entites_df\n",
      "+---------+-------------------+--------------------+\n",
      "|    genre|             entity|           sentiment|\n",
      "+---------+-------------------+--------------------+\n",
      "|Animation|      bromwell high|                 0.0|\n",
      "|   Comedy|      bromwell high|                 0.0|\n",
      "|Animation|            teacher|                 0.0|\n",
      "|   Comedy|            teacher|                 0.0|\n",
      "|Animation|            program|                 0.0|\n",
      "|   Comedy|            program|                 0.0|\n",
      "|Animation|        school life|                 0.0|\n",
      "|   Comedy|        school life|                 0.0|\n",
      "|Animation|            student|                 0.0|\n",
      "|   Comedy|            student|                 0.0|\n",
      "|Animation|            episode|                 0.0|\n",
      "|   Comedy|            episode|                 0.0|\n",
      "|Animation|teaching profession|                 0.0|\n",
      "|   Comedy|teaching profession|                 0.0|\n",
      "|Animation|            teacher|  -0.809999942779541|\n",
      "|   Comedy|            teacher|  -0.809999942779541|\n",
      "|Animation|            student|-0.04000000283122063|\n",
      "|   Comedy|            student|-0.04000000283122063|\n",
      "|Animation|            student|-0.01000000070780...|\n",
      "|   Comedy|            student|-0.01000000070780...|\n",
      "+---------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "grouped_entity_words\n",
      "+---------+--------------------+\n",
      "|    genre|            entities|\n",
      "+---------+--------------------+\n",
      "|    Crime|[giallo, element,...|\n",
      "|  Romance|[idea, film, cred...|\n",
      "| Thriller|[giallo, element,...|\n",
      "|Adventure|[biopic, ned kell...|\n",
      "|       NA|[lydia reed, the ...|\n",
      "+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "f1-score:  0.896551724137931\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.mllib.linalg import SparseVector, DenseVector, VectorUDT\n",
    "from pyspark.ml.linalg import SparseVector, DenseVector, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def sparse2dense(sp):\n",
    "    return DenseVector(sp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def separateGenres3(rec):\n",
    "    print(rec)\n",
    "    return [[genre, e, s] for (e, s) in rec.ENTITY_SENTIMENT for genre in rec.GENRE]\n",
    "\n",
    "def prepareDataset(collection, orientation, urls):\n",
    "    # Make sure we don't trigger Google Cloud API again\n",
    "    entity_documents_info = spark.read.parquet(\"hdfs://spark-master:8020/user/lmrd/\"+collection+\"/\"+orientation+\"_doc_info2.pq\")\n",
    "    print(\"emtity_documents_info\")\n",
    "    entity_documents_info.show(5)\n",
    "\n",
    "    genres_df = loadGenres(urls, orientation)\n",
    "    print(\"genres_df\")\n",
    "    genres_df.show(5)\n",
    "    \n",
    "    entity_documents_info = entity_documents_info.alias(\"df1\").join(genres_df.alias(\"df2\"), entity_documents_info.ID == genres_df.ID)#.select([\"df1.*\", \"df2.FILM_ID\", \"df2.GENRE\"])\n",
    "    print(\"entity_documents_info\")\n",
    "    entity_documents_info.show(5)\n",
    "    \n",
    "    grouped_entities = entity_documents_info.rdd.flatMap(separateGenres3)\n",
    "    grouped_entities.repartition(5)\n",
    "    print(\"grouped_entities\")\n",
    "    print(grouped_entities.take(5))\n",
    "    \n",
    "    grouped_entities_df = spark.createDataFrame(data=grouped_entities, schema=[\"genre\", \"entity\", \"sentiment\"])\n",
    "    grouped_entities_df.cache()\n",
    "    print(\"grouped_entites_df\")\n",
    "    grouped_entities_df.show()\n",
    "    \n",
    "    grouped_entity_words = grouped_entities_df.select([\"genre\", \"entity\"]).groupBy(\"genre\").agg(collect_list(\"entity\").alias(\"entities\"))\n",
    "    print(\"grouped_entity_words\")\n",
    "    grouped_entity_words.show(5)\n",
    "    \n",
    "    return grouped_entity_words\n",
    "\n",
    "def extractTFIDFDataframeAndModel(collection, orientation, urls):\n",
    "\n",
    "    grouped_entity_words = prepareDataset(collection, orientation, urls)\n",
    "    \n",
    "    # Create the dictionary\n",
    "    countVec = CountVectorizer(inputCol=\"entities\", outputCol=\"tf\")\n",
    "    #countVec = HashingTF(numFeatures=1024, inputCol=\"entities\", outputCol=\"tf\")\n",
    "    idf = IDF(inputCol=\"tf\", outputCol=\"tfidf\")\n",
    "    si = StringIndexer(inputCol=\"genre\", outputCol=\"genreId\")#, handleInvalid=\"keep\")\n",
    "    #nb = NaiveBayes(featuresCol=\"tfidf\", labelCol=\"genreId\", predictionCol=\"predictGenreId\")\n",
    "    rf = RandomForestClassifier(featuresCol=\"tfidf\", labelCol=\"genreId\", predictionCol=\"predictGenreId\")\n",
    "    #isModel = IndexToString(inputCol=nb.getPredictionCol(), outputCol=\"predictGenre\")\n",
    "    \n",
    "#    grouped_entity_words = si.fit(grouped_entity_words).transform(grouped_entity_words)\n",
    "    #pipeline = Pipeline(stages=[countVec, idf, si, nb])\n",
    "    pipeline = Pipeline(stages=[countVec, idf, si, rf])\n",
    "    \n",
    "    \n",
    "#    paramGrid = ParamGridBuilder() \\\n",
    "#        .addGrid(countVec.minTF, [1.0]) \\\n",
    "#        .addGrid(countVec.minDF, [1.0]) \\\n",
    "#        .build()\n",
    "    \n",
    "#    crossval = CrossValidator(estimator=pipeline,\n",
    "#                  estimatorParamMaps=paramGrid,\n",
    "#                  evaluator=MulticlassClassificationEvaluator(predictionCol=\"predictGenreId\", labelCol=\"genreId\", metricName=\"accuracy\"),\n",
    "#                  numFolds=3, parallelism=5)  # use 3+ folds in practice\n",
    "    \n",
    "#    cvModel = crossval.fit(grouped_entity_words)\n",
    "    cvModel = pipeline.fit(grouped_entity_words)\n",
    "    \n",
    "    dft = cvModel.transform(grouped_entity_words)\n",
    "    \n",
    "    eval = MulticlassClassificationEvaluator(predictionCol=\"predictGenreId\", labelCol=\"genreId\", metricName=\"accuracy\")\n",
    "    print(\"f1-score: \", eval.evaluate(dft))\n",
    "    \n",
    "    \n",
    "    return cvModel\n",
    "\n",
    "cvModel = extractTFIDFDataframeAndModel(collection, orientation, urlsCollection)\n",
    "\n",
    "#(tfidf, cvmodel, idf, siModel, isModel) = extractTFIDFDataframe(collection, orientation, urlsCollection)\n",
    "#tfidf.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.avgMetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def checkSentimentValue(x):\n",
    "    try:\n",
    "        f = float(x)\n",
    "        \n",
    "        return f\n",
    "    \n",
    "    except:\n",
    "        print(\"Wrong sentiment value \", f)\n",
    "        return 0\n",
    "    \n",
    "def extractEntitiesSetimentForReview(review_contents):\n",
    "    # Instantiates a client\n",
    "    client = language.LanguageServiceClient()\n",
    "        \n",
    "    document = types.Document(content = review_contents, \n",
    "                             type=enums.Document.Type.PLAIN_TEXT, language=\"en-US\")\n",
    "    tries=1\n",
    "    \n",
    "    while tries < 5:\n",
    "        try:\n",
    "            entities = client.analyze_entity_sentiment(document=document, encoding_type=\"UTF8\")\n",
    "            break\n",
    "        except:\n",
    "            f = open(\"/home/etienne/sparklog.txt\", mode=\"a\")\n",
    "\n",
    "            f.write(\"\"+str(entities)+\"\\n\")\n",
    "            f.close()\n",
    "            time.sleep(1)\n",
    "            \n",
    "            tries +=1\n",
    "            \n",
    "    \n",
    "    \n",
    "    # Make sure we have no duplicate entities. If we do, average their sentiment.\n",
    "    justLetters = re.compile(\"[^a-z ]\")\n",
    "    response = [o for o in zip([lemmatizer(justLetters.sub(\"\", entity.name.lower()), u\"NOUN\")[0] for entity in entities.entities], \n",
    "                               [checkSentimentValue(entity.sentiment.score) * checkSentimentValue(entity.sentiment.magnitude) \n",
    "                                    for entity in entities.entities])]\n",
    "    \n",
    "    \n",
    "#    response = sorted(response, key=lambda x: x[0])\n",
    "#    if (len(response)>1):\n",
    "#        response = reduce(collectEntities, response)\n",
    "    \n",
    "            \n",
    "    return response"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#from pyspark.mllib.linalg import SparseVector, DenseVector, VectorUDT\n",
    "from pyspark.ml.linalg import SparseVector, DenseVector, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def sparse2dense(sp):\n",
    "    return DenseVector(sp)\n",
    "\n",
    "udf_to_DenseVector = udf(sparse2dense, VectorUDT()) #Define UDF function\n",
    "\n",
    "tfidf2 = tfidf.withColumn(\"features\", udf_to_DenseVector(\"tfidf\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Animation']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def indexToLabel(cvModel, indexes):\n",
    "    return [cvModel.bestModel.stages[2].labels[index] for index in indexes]\n",
    "\n",
    "def indexToLabel2(cvModel, indexes):\n",
    "    return [cvModel.stages[2].labels[index] for index in indexes]\n",
    "\n",
    "indexToLabel2(cvModel, [0])\n",
    "#pipeline = cvModel.bestModel.explainParams()  #getEstimator()\n",
    "#siModel = pipeline.getStages()[2]\n",
    "\n",
    "#nb = NaiveBayes(featuresCol=\"tfidf\", labelCol=\"genreId\", predictionCol=\"predictGenreId\")\n",
    "\n",
    "#nb_model = nb.fit(tfidf2)\n",
    "\n",
    "#print(nb_model.pi)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#nbmodel_file = open(\"nbmodel.obj\", mode=\"ab\")\n",
    "nb_model.write().overwrite().save(\"nbmodel.obj\")\n",
    "tfidf.write.parquet(\"hdfs://spark-master:8020/user/lmrd/\"+collection+\"/\"+orientation+\"_tfidf.pq\", mode=\"overwrite\")\n",
    "cvmodel.write().overwrite().save(\"cvModel.obj\")\n",
    "idf.write().overwrite().save(\"idfModel.obj\")\n",
    "siModel.write().overwrite().save(\"siModel.obj\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nb_model = NaiveBayesModel.load(\"nbmodel.obj\")\n",
    "spark.read.parquet(\"hdfs://spark-master:8020/user/lmrd/\"+collection+\"/\"+orientation+\"_tfidf.pq\")\n",
    "cvmodel = CountVectorizerModel.load(\"cvModel.obj\")\n",
    "idf = IDFModel.load(\"idfModel.obj\")\n",
    "siModel = StringIndexerModel.load(\"siModel.obj\")\n",
    "isModel = IndexToString(inputCol=\"predictGenreId\", outputCol=\"predictGenre\", labels=siModel.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Path does not exist: hdfs://spark-master:8020/user/lmrd/test_reviews/pos_doc_info2.pq;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1253.parquet.\n: org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://spark-master:8020/user/lmrd/test_reviews/pos_doc_info2.pq;\n\tat org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:715)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$15.apply(DataSource.scala:389)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$15.apply(DataSource.scala:389)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:344)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:388)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:239)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:620)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-fceab98832e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepareDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_reviews\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murlsCollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-198671e914ba>\u001b[0m in \u001b[0;36mprepareDataset\u001b[0;34m(collection, orientation, urls)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepareDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Make sure we don't trigger Google Cloud API again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mentity_documents_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hdfs://spark-master:8020/user/lmrd/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_doc_info2.pq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"emtity_documents_info\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mentity_documents_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, *paths)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \"\"\"\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Path does not exist: hdfs://spark-master:8020/user/lmrd/test_reviews/pos_doc_info2.pq;'"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "ds = prepareDataset(\"test_reviews\", orientation, urlsCollection)\n",
    "\n",
    "ds.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Field \"genreId\" does not exist.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o27264.evaluate.\n: java.lang.IllegalArgumentException: Field \"genreId\" does not exist.\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:267)\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:267)\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:266)\n\tat org.apache.spark.ml.util.SchemaUtils$.checkNumericType(SchemaUtils.scala:71)\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator.evaluate(MulticlassClassificationEvaluator.scala:76)\n\tat sun.reflect.GeneratedMethodAccessor141.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-2e6662c8f34a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0meval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"predictGenreId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"genreId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1-score: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Field \"genreId\" does not exist.'"
     ]
    }
   ],
   "source": [
    "testpreds = cvModel.transform(ds)\n",
    "#testpreds.take(1)[0].tf\n",
    "\n",
    "eval = MulticlassClassificationEvaluator(predictionCol=\"predictGenreId\", labelCol=\"genreId\", metricName=\"accuracy\")\n",
    "print(\"f1-score: \", eval.evaluate(testpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pilot', 0.0), ('nothing', 0.0), ('movie', 0.0), ('web', 0.0), ('other', 0.0), ('costner', -0.16000000476837162), ('cheese factor', -0.010000000298023226), ('skeptic', 0.0), ('life', -0.03000000163912775), ('trailer', 0.0), ('coast guard', 0.0), ('trailer', 0.0), ('cheese', 0.0), ('film', 0.0), ('all', 0.0), ('film', 0.0), ('love story', 0.0), ('case', 0.0), ('each other', -0.040000001192092904), ('rescue', 0.0), ('action', 0.0), ('movie', -0.010000000298023226), ('kutcher', -0.03000000163912775), ('impression', 0.0), ('course', 0.0), ('is', -0.010000000298023226), ('surprise', 0.0), ('part', -0.040000001192092904), ('rescue action scene', 0.0), ('character', 0.0), ('struggle', -0.4899999833106996), ('some', 0.0), ('time', -0.040000001192092904), ('f word', -0.010000000298023226), ('tale', -0.010000000298023226), ('woundsa', 0.0), ('end', 0.0), ('each other', 0.010000000298023226), ('critic', -0.010000000298023226), ('officer', 0.0), ('moviea', 0.0), ('gentleman', 0.0), ('top gun', 0.0), ('movie', -0.08000000238418581), ('employee screening', 0.0), ('movie theater', 0.0), ('movie', 0.0), ('story', 0.7800000023841847), ('ashton kutcher', 0.0), ('anyone', 0.0), ('the guardian', 0.0), ('trailer', 0.010000000298023226), ('ad', 0.010000000298023226), ('lot', 0.0), ('all', 0.010000000298023226), ('way', 0.0), ('movie', 0.0), ('work', 0.25), ('film', 0.0), ('fan', 0.0), ('kevin costner', 0.25), ('tribute', 0.8099999570846563), ('hero', 0.0), ('the butterfly effect', 0.0), ('us coast guard', 0.0), ('actorit', 0.6400000190734865), ('thinking', 0.0), ('acting', 0.8099999570846563), ('that s show', 0.0), ('kelso', 0.0)]\n",
      "+--------------------+--------------------+--------------------+\n",
      "|            entities|            avg_sent|            std_sent|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[thinking, employ...|[0.0, -0.01500000...|[0.0, 0.160000011...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#revText=[\"I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\"]\n",
    "revText=[\"As others that have commented around the web... I'm a 130 pilot in the Coast Guard. Having said that, and being the skeptic I am, I went expecting the over-the-top cheese factors. There was some cheese, but all in all, not much.. and the film was pretty accurate.I watched the trailer again today. After seeing the film yesterday, I've realized the trailer gives the impression the movie is nothing but rescue after rescue action scenes. This isn't the case.The movie is truly more character/story driven than action. The inner struggles both Costner and Kutcher are dealing with.. Kutcher's is revealed further into than movie than Costner's is.Of course, there is a minor love story.. no surprise there. But for the most part, the movie tells the tale of two lives that come together, and after some time, help each other heal old wounds.As girlie as it sounds, Costner and, as much as I try not to like him, Kutcher do actually work quite well together and compliment each other very well in the movie.As critics have stated, you've seen it all before.. Top Gun, Officer and a Gentlemen, etc. But what movie hasn't been remade a million times.I can recall only one F word being spoken.. and can't really recall any other language.The movie is 2+ hours, and for some, may tend to get a little long towards the end.You'll laugh, you may cry, but I can honestly say, it was worth the $4 I paid.I hope you enjoy the movie\",\n",
    "         \"I work at a movie theater and every Thursday night we have an employee screening of one movie that comes out the next day...Today it was The Guardian. I saw the trailers and the ads and never expected much from it, and in no way really did i anticipate seeing this movie. Well turns out this movie was a lot more than I would have thought. It was a great story first of all. Ashton Kutcher and Kevin Costner did amazing acting work in this film. Being a big fan of That 70's Show I always found it hard thinking of Kutcher as anyone but Kelso despite the great acting he did in The Butterfly Effect, but after seeing this movie I think I might be able to finally look at him as a serious actor.It was also a great tribute to the unsung heroes of the U.S. Coast Guard.\"]\n",
    "revTextRdd = sc.parallelize(revText)\n",
    "\n",
    "lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "sc.broadcast(lemmatizer)\n",
    "\n",
    "#entitiesForTest = revTextRdd.flatMap(extractEntitiesSetimentForReview)\n",
    "entitiesForTest = revTextRdd.flatMap(extractEntitiesSetimentForReview)\n",
    "\n",
    "print(entitiesForTest.collect())\n",
    "schema1 = StructType(\n",
    "                [StructField(\"entity\", StringType(), False), \n",
    "                 StructField(\"sentiment\", FloatType(), False)])\n",
    "\n",
    "entitiesForTest_df = spark.createDataFrame(entitiesForTest, schema=schema1)\n",
    "\n",
    "\n",
    "entitiesForTest_df.registerTempTable(\"df\")\n",
    "grouped_entities_df2 = spark.sql(\"select ltrim(rtrim(entity)) as tentity, avg(sentiment) as avg_sent, stddev(sentiment) as std_sent from df group by tentity \")\n",
    "#grouped_entities_df2.registerTempTable(\"grouped_entities_df\")\n",
    "#grouped_entities_df3 = spark.sql(\"select genre, tentity as entity, avg_sent, std_sent from grouped_entities_df where abs(avg_sent)>0.3 order by genre, entity, avg_sent desc\")\n",
    "\n",
    "grouped_entities_df3 = grouped_entities_df2.withColumn(\"std_sent\", functions.when(functions.isnan(grouped_entities_df2.std_sent)==True, functions.abs(grouped_entities_df2.avg_sent)).otherwise(grouped_entities_df2.std_sent))\n",
    "\n",
    "\n",
    "entitiesForTest2_df = grouped_entities_df3.agg(collect_set('tentity').alias('entities')).crossJoin(grouped_entities_df3.agg(collect_set(\"avg_sent\").alias(\"avg_sent\"), collect_set(\"std_sent\").alias(\"std_sent\")))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#entitiesForTest_df.show()\n",
    "#entitiesForTest2_df = entitiesForTest_df.agg(collect_set('entity').alias('entities')).crossJoin(entitiesForTest_df.agg(collect_set('sentiment')).alias(\"sentiment\"))\n",
    "\n",
    "entitiesForTest2_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+\n",
      "|            entities|            avg_sent|            std_sent|                  tf|               tfidf|       rawPrediction|         probability|predictGenreId|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+\n",
      "|[thinking, employ...|[0.0, -0.01500000...|[0.0, 0.160000011...|(70083,[0,1,2,4,6...|(70083,[0,1,2,4,6...|[0.15818713450292...|[0.00790935672514...|          28.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+\n",
      "\n",
      "[0.158187134502924,3.1185045948203842,0.23472222222222222,3.0694444444444446,0.3601712614870509,0.17485380116959065,0.23253968253968255,0.4263888888888889,0.522671261487051,0.12698412698412698,0.23040935672514617,0.15555555555555556,0.18656015037593984,0.3130952380952381,0.158187134502924,0.4010964912280702,0.24429824561403507,0.712155388471178,0.3671157059314954,0.6706871345029239,0.1611111111111111,0.35138888888888886,0.16805555555555557,0.16805555555555557,0.44846491228070173,0.23596491228070177,0.12406015037593984,0.24906015037593984,6.230210944026735]\n",
      "[0.9920906432748537, 0.8440747702589808, 0.9882638888888889, 0.8465277777777778, 0.9819914369256475, 0.9912573099415205, 0.9883730158730158, 0.9786805555555556, 0.9738664369256474, 0.9936507936507937, 0.9884795321637427, 0.9922222222222222, 0.990671992481203, 0.9843452380952381, 0.9920906432748537, 0.9799451754385965, 0.9877850877192983, 0.9643922305764411, 0.9816442147034252, 0.9664656432748538, 0.9919444444444444, 0.9824305555555556, 0.9915972222222222, 0.9915972222222222, 0.9775767543859649, 0.9882017543859649, 0.993796992481203, 0.987546992481203, 0.6884894527986632]\n",
      "[26  9 11  0 14 20 23 22  5 12 10  6  2 25 16 27 13 21  4 18 15  7 24  8\n",
      " 19 17  3  1 28]\n",
      "['News', 'Talk-Show', 'Adult']\n"
     ]
    }
   ],
   "source": [
    "entitiesForTest3_df = cvModel.transform(entitiesForTest2_df)\n",
    "\n",
    "entitiesForTest3_df.show()\n",
    "\n",
    "indexToLabel2(cvModel, [int(entitiesForTest3_df.select(\"predictGenreId\").take(1)[0].predictGenreId)])\n",
    "\n",
    "scores = entitiesForTest3_df.select(\"rawPrediction\").collect()[0].rawPrediction\n",
    "print(scores)\n",
    "\n",
    "probs = [1-(1.0*s)/np.sum(scores) for s in scores]\n",
    "#probs = [exp(np.max(scores) - s) for s in scores]\n",
    "print(probs)\n",
    "print(np.argsort(scores))\n",
    "top = np.argsort(scores)[:-4:-1]\n",
    "\n",
    "print(indexToLabel2(cvModel, top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Animation', 'Talk-Show', 'Thriller', 'Adult', 'War', 'Horror', 'Documentary', 'NA', 'Biography', 'Comedy', 'Western', 'Fantasy', 'Romance', 'Family', 'Drama', 'Short', 'Sport', 'History', 'Film-Noir', 'Reality-TV', 'Music', 'Mystery', 'Musical', 'Sci-Fi', 'Game-Show', 'Adventure', 'Crime', 'Action', 'News']\n",
      "[-537.7891618608271,-587.9934842823056,-518.4590082407616,-585.93812581499,-543.6674228395556,-538.8842749128711,-553.6583065705015,-582.2730094151456,-537.4807382920243,-514.2212682051768,-556.3789659243172,-523.747313855792,-513.583636157141,-530.9484400011238,-506.7379617621209,-558.7893495978734,-554.9934586069586,-546.6821482616766,-561.8042696801848,-584.53159521691,-552.8948283999592,-534.1307261361959,-544.3075497937868,-529.3509095570462,-586.2027202433444,-518.7623805869365,-523.9627650786558,-514.3693191457652,-588.0464268898968]\n",
      "[0.9660284817794389, 0.9628571329036251, 0.9672495451858455, 0.9629869675164696, 0.9656571588445305, 0.9659593047568444, 0.9650260462956444, 0.9632184886726919, 0.966047964538911, 0.9675172383136407, 0.9648541853966811, 0.9669154890476829, 0.9675575167912933, 0.9664606022529988, 0.9679899501107707, 0.9647019242529247, 0.9649417062885368, 0.9654667221327656, 0.964511475244701, 0.9630758164246089, 0.9650742743270384, 0.9662595809251487, 0.9656167227665443, 0.966561516400099, 0.962970253393015, 0.967230381506254, 0.9669018792435771, 0.9675078861072697, 0.962853788580448]\n",
      "[28  1 24  3 19  7 18 15 10 16  6 20 17 22  4  5  0  8 21 13 23 26 11 25\n",
      "  2 27  9 12 14]\n",
      "+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------+------------+\n",
      "|            entities|collect_set(sentiment)|                  tf|            features|       rawPrediction|         probability|predictGenreId|predictGenre|\n",
      "+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------+------------+\n",
      "|[thinking, employ...|  [0.0, -0.03000000...|(76511,[0,1,3,5,1...|[1.0,1.0,0.0,1.0,...|[-537.78916186082...|[3.26372056603478...|          14.0|       Drama|\n",
      "+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "entitiesForTest3_df = cvmodel.transform(entitiesForTest2_df)\n",
    "\n",
    "entitiesForTest3_df = entitiesForTest3_df.withColumn(\"features\", udf_to_DenseVector(\"tf\"))\n",
    "\n",
    "entitiesForTest3_df = model.transform(entitiesForTest3_df)\n",
    "\n",
    "entitiesForTest3_df = isModel.transform(entitiesForTest3_df)\n",
    "\n",
    "print(isModel.getLabels())\n",
    "scores = entitiesForTest3_df.select(\"rawPrediction\").collect()[0].rawPrediction\n",
    "print(scores)\n",
    "\n",
    "probs = [1-(1.0*s)/np.sum(scores) for s in scores]\n",
    "#probs = [exp(np.max(scores) - s) for s in scores]\n",
    "print(probs)\n",
    "print(np.argsort(scores))\n",
    "entitiesForTest3_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#grouped_entities_df.show(5)\n",
    "grouped_entities_df.write.parquet(\"hdfs://spark-master:8020/user/lmrd/\"+urlsCollection+\"_\"+orientation+\"_grouped_entities.pq\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "grouped_entities_df = spark.read.parquet(\"hdfs://spark-master:8020/user/lmrd/\"+urlsCollection+\"_\"+orientation+\"_grouped_entities.pq\")\n",
    "\n",
    "grouped_entity_words = grouped_entities_df.select([\"genre\", \"entity\"]).groupBy(\"genre\").agg(collect_list(\"entity\").alias(\"entities\"))\n",
    "grouped_sentiment = grouped_entities_df.select([\"genre\", \"sentiment\"]).groupBy(\"genre\").agg(collect_list(\"sentiment\").alias(\"sentiment\"))\n",
    "#grouped_entity_words.show()\n",
    "#grouped_sentiment.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grouped_sentiment.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "\n",
    "# remove sentiment info for use by hashingTF/tfif\n",
    "\n",
    "# Load documents (one per line).\n",
    "\n",
    "countVec = CountVectorizer(inputCol=\"entities\", outputCol=\"tf\")\n",
    "cvmodel = countVec.fit(grouped_entity_words)\n",
    "\n",
    "tf = cvmodel.transform(grouped_entity_words)\n",
    "tf.show()\n",
    "#sc.broadcast(hashingTF)\n",
    "\n",
    "# While applying HashingTF only needs a single pass to the data, applying IDF needs two passes:\n",
    "# First to compute the IDF vector and second to scale the term frequencies by IDF.\n",
    "tf.cache()\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tfidf\").fit(tf)\n",
    "tfidf = idf.transform(tf)\n",
    "tfidf.show()\n",
    "# spark.mllib's IDF implementation provides an option for ignoring terms\n",
    "# which occur in less than a minimum number of documents.\n",
    "# In such cases, the IDF for these terms is set to 0.\n",
    "# This feature can be used by passing the minDocFreq value to the IDF constructor.\n",
    "# idfIgnore = IDF(minDocFreq=2).fit(tf)\n",
    "# tfidfIgnore = idfIgnore.transform(tf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import explode\n",
    "import numpy as np\n",
    "\n",
    "vocab = tfidf.select([\"genre\", \"tfidf\"])\n",
    "genreVocabs = dict()\n",
    "\n",
    "for genre in vocab.collect():\n",
    "    genreName = genre.genre\n",
    "    \n",
    "    t=genre.tfidf\n",
    "    genreVocabs[genreName] = t\n",
    "    \n",
    "globalVocab = list(cvmodel.vocabulary)\n",
    "    \n",
    "sc.broadcast(globalVocab)\n",
    "sc.broadcast(genreVocabs)\n",
    "\n",
    "def remapEntitiesByTfidf(row):\n",
    "    tfidfMappings = genreVocabs[row.genre]\n",
    "    tfIndex = globalVocab.index(row.entity)\n",
    "    tfidf = tfidfMappings[tfIndex]\n",
    "    \n",
    "    return Row(genre=row.genre, entity=row.entity, tfidf=float(tfidf), vocabIndex=int(tfIndex))\n",
    "    \n",
    "genreCorpora=dict()\n",
    "\n",
    "for genre in genreVocabs.keys():\n",
    "    genreEntities = tfidf.where(tfidf.genre==genre).select(\"genre\", explode(\"entities\").alias(\"entity\"))\n",
    "    \n",
    "    #genreEntities.show()\n",
    "    \n",
    "    #data = genreEntities.rdd.map(remapEntitiesByTfidf)\n",
    "\n",
    "    entitiesByTfidf = spark.createDataFrame(data=genreEntities.rdd.map(remapEntitiesByTfidf), schema=[\"entity\", \"genre\", \"tfidf\", \"vocabIndex\"])\n",
    "    #entitiesByTfidf.show()\n",
    "    entitiesByTfidf = entitiesByTfidf.join(grouped_entities_df, on=[\"genre\", \"entity\"], how=\"inner\" ).groupBy([\"genre\", \"entity\", \"tfidf\", \"vocabIndex\"]).avg(\"sentiment\").sort(\"tfidf\", ascending=False)\n",
    "    \n",
    "    genreCorpora[genre] = entitiesByTfidf\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "for (genreName, corpus) in genreCorpora.items():\n",
    "    print(genreName)\n",
    "    df = corpus.select(col(\"genre\"), col(\"entity\"), col(\"tfidf\"), col(\"vocabIndex\"), col(\"avg(sentiment)\").alias(\"sentiment\"))\n",
    "\n",
    "    df.write.parquet(\"hdfs://spark-master:8020/user/lmrd/\"+genreName+\"_\"+orientation+\"_tfidf.pq\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "genreNames=[\"crime\", \"romance\", \"thriller\", \"adventure\", \"na\", \"drama\", \"war\", \"documentary\", \"reality-tv\", \n",
    "            \"family\", \"fantasy\", \"game-show\", \"adult\", \"history\", \"mystery\", \"musical\", \"animation\", \"music\", \n",
    "            \"film-noir\", \"horror\", \"short\", \"western\", \"biography\", \"comedy\", \"action\", \"sport\", \"talk-show\", \n",
    "            \"sci-fi\", \"news\"]\n",
    "\n",
    "crime_df = spark.read.parquet(\"hdfs://spark-master:8020/user/lmrd/Crime_pos_tfidf.pq\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "crime_df.show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "crime_df.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
