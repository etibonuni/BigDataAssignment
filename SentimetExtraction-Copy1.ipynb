{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up HDFS and Google credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://sp-master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://sp-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://sp-master:7077 appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"./imdb-e9e7ce7a779d.json\"\n",
    "os.environ[\"HDFSCLI_CONFIG\"]=\"./.hdfscli.cfg\"\n",
    "os.environ[\"HADOOP_CONF_DIR\"]=\"/opt/hadoop-3.1.0/etc/hadoop\"\n",
    "sc.environment[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/imdb-e9e7ce7a779d.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List filenames of reviews from HDFS and parallelize in preparation from processing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from hdfs import Config\n",
    "import pandas as pd\n",
    "\n",
    "#9870\n",
    "#from hdfs3 import HDFileSystem\n",
    "#hdfs = HDFileSystem(u\"localhost\", 9000)\n",
    "\n",
    "\n",
    "hdfs_prefix=\"hdfs://localhost:9000/\"\n",
    "reviews_path=\"/user/lmrd/reviews\"\n",
    "\n",
    "    \n",
    "def getReviewFilenames(path):\n",
    "    client = Config().get_client('dev')\n",
    "    files = client.list(path)\n",
    "    \n",
    "    files_df = pd.DataFrame(data={\"fileNames\":files})\n",
    "    \n",
    "    files_df[\"index\"] = files_df[\"fileNames\"].str.extract('(.*)_.*\\..*', expand = True).apply(pd.to_numeric)\n",
    "\n",
    "    files_df = files_df.sort_values(by=\"index\")\n",
    "   # print(files_df)\n",
    "    \n",
    "    return [hdfs_prefix+path+\"/\"+f for f in files_df[\"fileNames\"]]\n",
    "\n",
    "pos_files_rdd = sc.parallelize(getReviewFilenames(reviews_path+\"/pos\"))\n",
    "#pos_files_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelise the reviews and use Google NLP API to extract entities and related sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "from functools import reduce\n",
    "\n",
    "def collectEntities(x, y):\n",
    "    # The first reduce call doesn't pass a list for x, so we need to check for that.\n",
    "    if not isinstance(x, list):\n",
    "        x=[x]\n",
    "        \n",
    "\n",
    "    xd = dict(x)\n",
    "    #print(xd)\n",
    "    \n",
    "    if not isinstance(y, list):\n",
    "        y = [y]\n",
    "        \n",
    "    for ye in y:\n",
    "        if ye[0] in xd:\n",
    "            try:\n",
    "                xd[ye[0]] = (xd[ye[0]]+ye[1])/2\n",
    "            except:\n",
    "                Null\n",
    "        else:\n",
    "            xd[ye[0]] = ye[1]\n",
    "    \n",
    "    return [o for o in xd.items()]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "def extractEntitiesSetiment(fileObj):\n",
    "    # Instantiates a client\n",
    "    client = language.LanguageServiceClient()\n",
    "    \n",
    "    review_contents = fileObj\n",
    "        \n",
    "    #print(review_contents)\n",
    "    \n",
    "    document = types.Document(content = review_contents, \n",
    "                             type=enums.Document.Type.PLAIN_TEXT)\n",
    "    \n",
    "    entities = client.analyze_entity_sentiment(document=document, encoding_type=\"UTF8\")\n",
    "    \n",
    "    # Make sure we have no duplicate entities. If we do, average their sentiment.\n",
    "    justLetters = re.compile(\"[^a-z ]\")\n",
    "    response = [o for o in zip([justLetters.sub(\"\", entity.name.lower()) for entity in entities.entities], [entity.sentiment.score * entity.sentiment.magnitude for entity in entities.entities])]\n",
    "    response = sorted(response, key=lambda x: x[0])\n",
    "    response = reduce(collectEntities, response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "file_objs = map(lambda f: ' '.join(list(sc.hadoopFile(f, \"org.apache.hadoop.mapred.TextInputFormat\", \n",
    "                                              \"org.apache.hadoop.io.Text\", \n",
    "                                              \"org.apache.hadoop.io.Text\").values().collect())), pos_files_rdd.collect())\n",
    "\n",
    "#file_objs = sc.parallelize(file_objs)\n",
    "#entity_documents_info = file_objs.map(extractEntitiesSetiment)\n",
    "\n",
    "\n",
    "#entity_documents_info.cache()\n",
    "#print(entity_documents_info.take(1))\n",
    "#print(entity_documents_info.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = sc.wholeTextFiles(\"hdfs://sp-master:8020/user/lmrd/reviews/pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hdfs://sp-master:8020/user/lmrd/reviews/pos/0_9.txt',\n",
       "  'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'),\n",
       " ('hdfs://sp-master:8020/user/lmrd/reviews/pos/10000_8.txt',\n",
       "  'Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.'),\n",
       " ('hdfs://sp-master:8020/user/lmrd/reviews/pos/10001_10.txt',\n",
       "  'Brilliant over-acting by Lesley Ann Warren. Best dramatic hobo lady I have ever seen, and love scenes in clothes warehouse are second to none. The corn on face is a classic, as good as anything in Blazing Saddles. The take on lawyers is also superb. After being accused of being a turncoat, selling out his boss, and being dishonest the lawyer of Pepto Bolt shrugs indifferently \"I\\'m a lawyer\" he says. Three funny words. Jeffrey Tambor, a favorite from the later Larry Sanders show, is fantastic here too as a mad millionaire who wants to crush the ghetto. His character is more malevolent than usual. The hospital scene, and the scene where the homeless invade a demolition site, are all-time classics. Look for the legs scene and the two big diggers fighting (one bleeds). This movie gets better each time I see it (which is quite often).'),\n",
       " ('hdfs://sp-master:8020/user/lmrd/reviews/pos/10002_7.txt',\n",
       "  'This is easily the most underrated film inn the Brooks cannon. Sure, its flawed. It does not give a realistic view of homelessness (unlike, say, how Citizen Kane gave a realistic view of lounge singers, or Titanic gave a realistic view of Italians YOU IDIOTS). Many of the jokes fall flat. But still, this film is very lovable in a way many comedies are not, and to pull that off in a story about some of the most traditionally reviled members of society is truly impressive. Its not The Fisher King, but its not crap, either. My only complaint is that Brooks should have cast someone else in the lead (I love Mel as a Director and Writer, not so much as a lead).'),\n",
       " ('hdfs://sp-master:8020/user/lmrd/reviews/pos/10003_8.txt',\n",
       "  'This is not the typical Mel Brooks film. It was much less slapstick than most of his movies and actually had a plot that was followable. Leslie Ann Warren made the movie, she is such a fantastic, under-rated actress. There were some moments that could have been fleshed out a bit more, and some scenes that could probably have been cut to make the room to do so, but all in all, this is worth the price to rent and see it. The acting was good overall, Brooks himself did a good job without his characteristic speaking to directly to the audience. Again, Warren was the best actor in the movie, but \"Fume\" and \"Sailor\" both played their parts well.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def checkSentimentValue(x):\n",
    "    try:\n",
    "        f = float(x)\n",
    "        \n",
    "        return f\n",
    "    \n",
    "    except:\n",
    "        print(\"Wrong sentiment value \", f)\n",
    "        return 0\n",
    "    \n",
    "def extractEntitiesSetiment2(fileObj):\n",
    "    # Instantiates a client\n",
    "    client = language.LanguageServiceClient()\n",
    "    \n",
    "    review_contents = fileObj[1]\n",
    "        \n",
    "    #print(review_contents)\n",
    "    document = types.Document(content = review_contents, \n",
    "                             type=enums.Document.Type.PLAIN_TEXT)\n",
    "    \n",
    "    entities = client.analyze_entity_sentiment(document=document, encoding_type=\"UTF8\")\n",
    "    \n",
    "    # Make sure we have no duplicate entities. If we do, average their sentiment.\n",
    "    justLetters = re.compile(\"[^a-z ]\")\n",
    "    response = [o for o in zip([justLetters.sub(\"\", entity.name.lower()) for entity in entities.entities], [checkSentimentValue(entity.sentiment.score) * checkSentimentValue(entity.sentiment.magnitude) for entity in entities.entities])]\n",
    "    response = sorted(response, key=lambda x: x[0])\n",
    "    response = reduce(collectEntities, response)\n",
    "    #print(fileObj[0], response)\n",
    "    try:\n",
    "        fid = int(fileObj[0])\n",
    "    except:\n",
    "        fid=0\n",
    "    \n",
    "    return (fileObj[0], response)\n",
    "\n",
    "def extractOrdering(rec):\n",
    "    filenameRegexp = \".*/([0-9]*)_.*\\.txt$\"\n",
    "    r = re.search(filenameRegexp, rec[0])\n",
    "\n",
    "    return (int(r.groups()[0])+1, rec[1])\n",
    "    #hdfs://localhost:9000/user/lmrd/reviews/pos/3467_7.txt\n",
    "\n",
    "#sc.broadcast(filenameRegexp)\n",
    "filesRdd = tf.map(extractOrdering)\n",
    "\n",
    "#schema1 = StructType([\n",
    "#    StructField(\"ID\", IntegerType(), False),\n",
    "#    StructField(\"GENRE\", ArrayType(\n",
    "#            StructField(\"ENTITY\", StringType(), False), \n",
    "#            StructField(\"SENTIMENT\", FloatType(), False)), nullable=True)])\n",
    "\n",
    "entity_documents_info = filesRdd.map(extractEntitiesSetiment2)\n",
    "entity_documents_info.cache()\n",
    "#entity_documents_info.saveAsTextFile(\"hdfs://sp-master:8020/user/lmrd/reviews/temp_pos3.txt\")\n",
    "\n",
    "\n",
    "entity_documents_info = spark.createDataFrame(filesRdd.map(extractEntitiesSetiment2), schema=[\"ID\", \"ENTITIY_SENTIMENT\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entity_documents_info = spark.createDataFrame(filesRdd.map(extractEntitiesSetiment2), schema=[\"ID\", \"ENTITIY_SENTIMENT\"])\n",
    "\n",
    "entity_documents_info.write.parquet(\"hdfs://spark-master:8020/user/lmrd/reviews/pos_doc_info.pq\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'),\n",
       " (10000,\n",
       "  'Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.'),\n",
       " (10001,\n",
       "  'Brilliant over-acting by Lesley Ann Warren. Best dramatic hobo lady I have ever seen, and love scenes in clothes warehouse are second to none. The corn on face is a classic, as good as anything in Blazing Saddles. The take on lawyers is also superb. After being accused of being a turncoat, selling out his boss, and being dishonest the lawyer of Pepto Bolt shrugs indifferently \"I\\'m a lawyer\" he says. Three funny words. Jeffrey Tambor, a favorite from the later Larry Sanders show, is fantastic here too as a mad millionaire who wants to crush the ghetto. His character is more malevolent than usual. The hospital scene, and the scene where the homeless invade a demolition site, are all-time classics. Look for the legs scene and the two big diggers fighting (one bleeds). This movie gets better each time I see it (which is quite often).'),\n",
       " (10002,\n",
       "  'This is easily the most underrated film inn the Brooks cannon. Sure, its flawed. It does not give a realistic view of homelessness (unlike, say, how Citizen Kane gave a realistic view of lounge singers, or Titanic gave a realistic view of Italians YOU IDIOTS). Many of the jokes fall flat. But still, this film is very lovable in a way many comedies are not, and to pull that off in a story about some of the most traditionally reviled members of society is truly impressive. Its not The Fisher King, but its not crap, either. My only complaint is that Brooks should have cast someone else in the lead (I love Mel as a Director and Writer, not so much as a lead).'),\n",
       " (10003,\n",
       "  'This is not the typical Mel Brooks film. It was much less slapstick than most of his movies and actually had a plot that was followable. Leslie Ann Warren made the movie, she is such a fantastic, under-rated actress. There were some moments that could have been fleshed out a bit more, and some scenes that could probably have been cut to make the room to do so, but all in all, this is worth the price to rent and see it. The acting was good overall, Brooks himself did a good job without his characteristic speaking to directly to the audience. Again, Warren was the best actor in the movie, but \"Fume\" and \"Sailor\" both played their parts well.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesRdd.take(5)\n",
    "#entity_documents_info.show(5)\n",
    "#entity_documents_info.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load genre information from file (previously collected using IMDB API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------+---+\n",
      "|FILM_ID|              GENRE|ID_TEMP| ID|\n",
      "+-------+-------------------+-------+---+\n",
      "| 453418|[Animation, Comedy]|      0|  1|\n",
      "| 453418|[Animation, Comedy]|      1|  2|\n",
      "| 453418|[Animation, Comedy]|      2|  3|\n",
      "|  64354|           [Comedy]|      3|  4|\n",
      "|  64354|           [Comedy]|      4|  5|\n",
      "+-------+-------------------+-------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import base64\n",
    "from functools import reduce\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window as W\n",
    "\n",
    "def decodeGenre(x):\n",
    "    try: \n",
    "        g = pickle.loads(base64.b64decode(x[2:-1]), encoding=\"bytes\") \n",
    "        if (len(g)==0):\n",
    "            return [\"NA\"]\n",
    "        else:\n",
    "            return g\n",
    "    except:\n",
    "        return [\"NA\"]    \n",
    "        \n",
    "        \n",
    "genres = pd.read_csv(\"Data/genres_train_urls_pos.csv\", sep=\"\\t\", index_col=0, usecols=[1, 2, 3])\n",
    "#print(genres.head())\n",
    "genres = genres.fillna(value=\"b''\")\n",
    "genres[\"GENRE\"] = genres[\"GENRE\"].apply(decodeGenre) \n",
    "\n",
    "# Get list of unique genre values\n",
    "#unique_genres = set(reduce(lambda x, y: x+y, genres[\"GENRE\"].values))\n",
    "#print(unique_genres)\n",
    "\n",
    "#print(genres)\n",
    "#print(genres[[\"ID\", \"GENRE\"]])\n",
    "#z = zip(genres[\"ID\"], genres[\"GENRE\"])\n",
    "\n",
    "\n",
    "#genres_rdd = sc.parallelize([(int(k)-1, v[0], v[1]) for (k, v) in genres.iteritems()])\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"FILM_ID\", IntegerType(), True),\n",
    "    StructField(\"GENRE\", ArrayType(StringType(), containsNull=True), True)])\n",
    "\n",
    "genres_df = spark.createDataFrame(genres, schema)\n",
    "\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# This will return a new DF with all the columns + id\n",
    "genres_df = genres_df.withColumn(\"ID_TEMP\", monotonically_increasing_id())#.limit(10)\n",
    "\n",
    "genres_df = genres_df.withColumn(\"ID\",F.row_number().over(W.orderBy(\"ID_TEMP\"))).select()#.limit(10)\n",
    "\n",
    "#df1.withColumn(\"idx\", F.row_number())\n",
    "genres_df.show(5)\n",
    "#genres_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_documents_info = entity_documents_info.alias(\"df1\").join(genres_df.alias(\"df2\"), entity_documents_info.ID == genres_df.ID)#.select([\"df1.*\", \"df2.FILM_ID\", \"df2.GENRE\"])\n",
    "\n",
    "entity_documents_info.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the document-entity-sentiment rdd with the genre rdd.\n",
    "There should be exactly the same number of reviews as records in the genres rdd."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "entity_documents_info = entity_documents_info.zip(genres_rdd)\n",
    "\n",
    "#entity_documents_info.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group documents by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[genre: string, entity: string, sentiment: double]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separateGenres(rec):\n",
    "    print(len(rec))\n",
    "    return [[genre, rec[0]] for genre in rec[1][1]]\n",
    "\n",
    "def separateGenres2(rec):\n",
    "    return [[genre, e, s] for (e, s) in rec[0] for genre in rec[1][1]]\n",
    "\n",
    "def separateGenres3(rec):\n",
    "    print(rec)\n",
    "    return [[genre, e, s] for (e, s) in rec.ENTITIY_SENTIMENT for genre in rec.GENRE]\n",
    "    \n",
    "#grouped_entities = entity_documents_info.flatMap(separateGenres).reduceByKey(collectEntities)\n",
    "grouped_entities = entity_documents_info.rdd.flatMap(separateGenres3)\n",
    "\n",
    "grouped_entities_df = spark.createDataFrame(data=grouped_entities, schema=[\"genre\", \"entity\", \"sentiment\"])\n",
    "#grouped_entities_df.show()\n",
    "grouped_entities_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+--------------------+\n",
      "|    genre|        entity|           sentiment|\n",
      "+---------+--------------+--------------------+\n",
      "|Animation|        anyone|-0.04000000119209...|\n",
      "|   Comedy|        anyone|-0.04000000119209...|\n",
      "|Animation|ashton kutcher|                 0.0|\n",
      "|   Comedy|ashton kutcher|                 0.0|\n",
      "|Animation|   ben randall|0.040000001192092904|\n",
      "|   Comedy|   ben randall|0.040000001192092904|\n",
      "|Animation|     character|                 0.0|\n",
      "|   Comedy|     character|                 0.0|\n",
      "|Animation|        comedy|                 0.0|\n",
      "|   Comedy|        comedy|                 0.0|\n",
      "|Animation|      emotions|                 0.0|\n",
      "|   Comedy|      emotions|                 0.0|\n",
      "|Animation|       friends|                 0.0|\n",
      "|   Comedy|       friends|                 0.0|\n",
      "|Animation|          half|                 0.0|\n",
      "|   Comedy|          half|                 0.0|\n",
      "|Animation|  jake fischer|                 0.0|\n",
      "|   Comedy|  jake fischer|                 0.0|\n",
      "|Animation| kevin costner|                 0.0|\n",
      "|   Comedy| kevin costner|                 0.0|\n",
      "+---------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_entities_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import collect_list\n",
    "\n",
    "#def removeSentiment(x):\n",
    "#    entities = list()\n",
    "#    for xe in x:\n",
    "#        entities.append(xe[0])\n",
    "#        \n",
    "#    return entities\n",
    "#\n",
    "#grouped_entity_words = grouped_entities.values().map(removeSentiment)\n",
    "\n",
    "grouped_entity_words = grouped_entities_df.select([\"genre\", \"entity\"]).groupBy(\"genre\").agg(collect_list(\"entity\").alias(\"entities\"))\n",
    "grouped_sentiment = grouped_entities_df.select([\"genre\", \"sentiment\"]).groupBy(\"genre\").agg(collect_list(\"sentiment\").alias(\"sentiment\"))\n",
    "#grouped_entity_words.show()\n",
    "#grouped_sentiment.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|    genre|           sentiment|\n",
      "+---------+--------------------+\n",
      "|  Romance|[0.0, 0.010000000...|\n",
      "|    Drama|[0.0, 0.010000000...|\n",
      "|Animation|[-0.0400000011920...|\n",
      "|   Comedy|[-0.0400000011920...|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_sentiment.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+\n",
      "|    genre|            entities|                  tf|\n",
      "+---------+--------------------+--------------------+\n",
      "|  Romance|[acting moments, ...|(216,[0,1,2,3,4,5...|\n",
      "|    Drama|[acting moments, ...|(216,[0,1,2,3,4,5...|\n",
      "|Animation|[anyone, ashton k...|(216,[0,1,2,3,5,6...|\n",
      "|   Comedy|[anyone, ashton k...|(216,[0,1,2,3,5,6...|\n",
      "+---------+--------------------+--------------------+\n",
      "\n",
      "+---------+--------------------+--------------------+--------------------+\n",
      "|    genre|            entities|                  tf|               tfidf|\n",
      "+---------+--------------------+--------------------+--------------------+\n",
      "|  Romance|[acting moments, ...|(216,[0,1,2,3,4,5...|(216,[0,1,2,3,4,5...|\n",
      "|    Drama|[acting moments, ...|(216,[0,1,2,3,4,5...|(216,[0,1,2,3,4,5...|\n",
      "|Animation|[anyone, ashton k...|(216,[0,1,2,3,5,6...|(216,[0,1,2,3,5,6...|\n",
      "|   Comedy|[anyone, ashton k...|(216,[0,1,2,3,5,6...|(216,[0,1,2,3,5,6...|\n",
      "+---------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "\n",
    "# remove sentiment info for use by hashingTF/tfif\n",
    "\n",
    "# Load documents (one per line).\n",
    "\n",
    "countVec = CountVectorizer(inputCol=\"entities\", outputCol=\"tf\")\n",
    "cvmodel = countVec.fit(grouped_entity_words)\n",
    "\n",
    "tf = cvmodel.transform(grouped_entity_words)\n",
    "tf.show()\n",
    "#sc.broadcast(hashingTF)\n",
    "\n",
    "# While applying HashingTF only needs a single pass to the data, applying IDF needs two passes:\n",
    "# First to compute the IDF vector and second to scale the term frequencies by IDF.\n",
    "tf.cache()\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tfidf\").fit(tf)\n",
    "tfidf = idf.transform(tf)\n",
    "tfidf.show()\n",
    "# spark.mllib's IDF implementation provides an option for ignoring terms\n",
    "# which occur in less than a minimum number of documents.\n",
    "# In such cases, the IDF for these terms is set to 0.\n",
    "# This feature can be used by passing the minDocFreq value to the IDF constructor.\n",
    "# idfIgnore = IDF(minDocFreq=2).fit(tf)\n",
    "# tfidfIgnore = idfIgnore.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+------------------+----------+--------------------+\n",
      "| genre|            entity|             tfidf|vocabIndex|      avg(sentiment)|\n",
      "+------+------------------+------------------+----------+--------------------+\n",
      "|Comedy|            movies|1.8325814637483102|        74|-0.00250000007450...|\n",
      "|Comedy|               one|1.0216512475319814|        20|                 0.0|\n",
      "|Comedy|         character|1.0216512475319814|        24|                 0.0|\n",
      "|Comedy|            anyone|1.0216512475319814|        16|-0.02000000059604...|\n",
      "|Comedy|               any|1.0216512475319814|        26| -0.2449999916553498|\n",
      "|Comedy|       performance|1.0216512475319814|        23|                 0.0|\n",
      "|Comedy|          anything|1.0216512475319814|        25|                 0.0|\n",
      "|Comedy|        characters|0.9162907318741551|       186|                 0.0|\n",
      "|Comedy|           hatches|0.9162907318741551|       203|                 0.0|\n",
      "|Comedy|              line|0.9162907318741551|       187|                 0.0|\n",
      "|Comedy|              hint|0.9162907318741551|       210|                 0.0|\n",
      "|Comedy|       distraction|0.9162907318741551|       208|                 0.0|\n",
      "|Comedy|day after tomorrow|0.9162907318741551|       213|                 0.0|\n",
      "|Comedy|         downfalls|0.9162907318741551|       215|-0.09000000715255752|\n",
      "|Comedy|           problem|0.9162907318741551|       201|0.010000000298023226|\n",
      "|Comedy|           nitpick|0.9162907318741551|       197|                 0.0|\n",
      "|Comedy|           theatre|0.9162907318741551|       200|                 0.0|\n",
      "|Comedy|           success|0.9162907318741551|       185|                 0.0|\n",
      "|Comedy|              tear|0.9162907318741551|       199|-0.16000000476837162|\n",
      "|Comedy|      movie makers|0.9162907318741551|       207|                 0.0|\n",
      "+------+------------------+------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import explode\n",
    "import numpy as np\n",
    "\n",
    "vocab = tfidf.select([\"genre\", \"tfidf\"])\n",
    "genreVocabs = dict()\n",
    "\n",
    "for genre in vocab.collect():\n",
    "    genreName = genre.genre\n",
    "    \n",
    "    t=genre.tfidf\n",
    "    genreVocabs[genreName] = t\n",
    "    \n",
    "globalVocab = list(cvmodel.vocabulary)\n",
    "    \n",
    "sc.broadcast(globalVocab)\n",
    "sc.broadcast(genreVocabs)\n",
    "\n",
    "def remapEntitiesByTfidf(row):\n",
    "    tfidfMappings = genreVocabs[row.genre]\n",
    "    tfIndex = globalVocab.index(row.entity)\n",
    "    tfidf = tfidfMappings[tfIndex]\n",
    "    \n",
    "    return Row(genre=row.genre, entity=row.entity, tfidf=float(tfidf), vocabIndex=int(tfIndex))\n",
    "    \n",
    "genreCorpora=dict()\n",
    "\n",
    "for genre in genreVocabs.keys():\n",
    "    genreEntities = tfidf.where(tfidf.genre==genre).select(\"genre\", explode(\"entities\").alias(\"entity\"))\n",
    "    \n",
    "    #genreEntities.show()\n",
    "    \n",
    "    #data = genreEntities.rdd.map(remapEntitiesByTfidf)\n",
    "\n",
    "    entitiesByTfidf = spark.createDataFrame(data=genreEntities.rdd.map(remapEntitiesByTfidf), schema=[\"entity\", \"genre\", \"tfidf\", \"vocabIndex\"])\n",
    "    #entitiesByTfidf.show()\n",
    "    entitiesByTfidf = entitiesByTfidf.join(grouped_entities_df, on=[\"genre\", \"entity\"], how=\"inner\" ).groupBy([\"genre\", \"entity\", \"tfidf\", \"vocabIndex\"]).avg(\"sentiment\").sort(\"tfidf\", ascending=False)\n",
    "    \n",
    "    genreCorpora[genre] = entitiesByTfidf\n",
    "    \n",
    "genreCorpora[\"Comedy\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 178 in stage 122.0 failed 1 times, most recent failure: Lost task 178.0 in stage 122.0 (TID 4756, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 229, in main\n    process()\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 224, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\nTypeError: 'NoneType' object is not iterable\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:153)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 229, in main\n    process()\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 224, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\nTypeError: 'NoneType' object is not iterable\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-c805fc8b7bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mentitiesByTfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \"\"\"\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 178 in stage 122.0 failed 1 times, most recent failure: Lost task 178.0 in stage 122.0 (TID 4756, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 229, in main\n    process()\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 224, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\nTypeError: 'NoneType' object is not iterable\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:153)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 229, in main\n    process()\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 224, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\nTypeError: 'NoneType' object is not iterable\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "entitiesByTfidf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([('British', 0.0),\n",
       "   ('Bromwell High', 0.03000000163912775),\n",
       "   ('Keisha', 0.0),\n",
       "   ('Latrina', 0.0),\n",
       "   ('Natella', 0.0),\n",
       "   ('South London Public School', 0.0),\n",
       "   ('characters', 0.040000001192092904),\n",
       "   ('correctness', 0.0),\n",
       "   ('cross section', 0.0),\n",
       "   ('episode', 0.0),\n",
       "   ('escapades', 0.0),\n",
       "   ('fun', 0.36000002861023006),\n",
       "   ('laughter', 0.0),\n",
       "   ('parody', -0.010000000298023226),\n",
       "   ('protagonists', 0.0),\n",
       "   ('show', -0.010000000298023226),\n",
       "   ('shows', 0.7200000572204601),\n",
       "   ('society', 0.040000001192092904),\n",
       "   ('students', 0.0),\n",
       "   ('subject', 0.020000000596046452),\n",
       "   ('teachers', 0.0),\n",
       "   ('term', 0.8099999570846563),\n",
       "   ('want', 0.4899999833106996),\n",
       "   ('window', 0.0),\n",
       "   ('De Niro', 0.010000000298023226),\n",
       "   ('Fonda', 0.010000000298023226),\n",
       "   ('acting', 0.25),\n",
       "   ('average', 0.010000000298023226),\n",
       "   ('best.', 0.0),\n",
       "   ('blue collar', 0.010000000298023226),\n",
       "   ('cinematography', 0.0),\n",
       "   ('coartship', 0.010000000298023226),\n",
       "   ('drama', 0.16000000476837162),\n",
       "   ('fans', 0.010000000298023226),\n",
       "   ('film', -0.2750000059604645),\n",
       "   ('illiteracy', 0.010000000298023226),\n",
       "   ('level.It', 0.010000000298023226),\n",
       "   ('life', 0.0),\n",
       "   ('lives', 0.040000001192092904),\n",
       "   ('love stories', 0.0),\n",
       "   ('love story movie', 0.08000000238418581),\n",
       "   ('people', 0.09249999903142449),\n",
       "   ('screenplay', 0.010000000298023226),\n",
       "   ('script', 0.010000000298023226),\n",
       "   ('story', 0.0),\n",
       "   ('subject matter', 0.010000000298023226)],\n",
       "  SparseVector(1048576, {11359: 0.4418, 17222: 1.5404, 67697: 1.5404, 102356: 1.5404, 115481: 1.2528, 157446: 1.5404, 161112: 1.5404, 166699: 1.0296, 226815: 1.0296, 227381: 1.5404, 245794: 1.5404, 280068: 1.5404, 293798: 0.2412, 296995: 1.5404, 299097: 1.5404, 307547: 1.5404, 316140: 1.5404, 364197: 1.5404, 371597: 1.2528, 465091: 1.5404, 466911: 1.0296, 513325: 1.5404, 519537: 1.2528, 531473: 1.5404, 561197: 1.5404, 563407: 1.5404, 597390: 1.0296, 608482: 1.5404, 613803: 1.5404, 614062: 1.5404, 615108: 1.5404, 647992: 1.5404, 653886: 1.2528, 666291: 1.5404, 685591: 1.5404, 692651: 1.5404, 696384: 1.5404, 766492: 0.8473, 769269: 0.4418, 823871: 1.2528, 873376: 1.5404, 885101: 1.5404, 889687: 1.5404, 913443: 1.0296, 915917: 1.5404, 940202: 1.5404})),\n",
       " ([('British', 0.0),\n",
       "   ('Bromwell High', 0.03000000163912775),\n",
       "   ('Keisha', 0.0),\n",
       "   ('Latrina', 0.0),\n",
       "   ('Natella', 0.0),\n",
       "   ('South London Public School', 0.0),\n",
       "   ('characters', 0.040000001192092904),\n",
       "   ('correctness', 0.0),\n",
       "   ('cross section', 0.0),\n",
       "   ('episode', 0.0),\n",
       "   ('escapades', 0.0),\n",
       "   ('fun', 0.36000002861023006),\n",
       "   ('laughter', 0.0),\n",
       "   ('parody', -0.010000000298023226),\n",
       "   ('protagonists', 0.0),\n",
       "   ('show', -0.010000000298023226),\n",
       "   ('shows', 0.7200000572204601),\n",
       "   ('society', 0.040000001192092904),\n",
       "   ('students', 0.0),\n",
       "   ('subject', 0.020000000596046452),\n",
       "   ('teachers', 0.0),\n",
       "   ('term', 0.8099999570846563),\n",
       "   ('want', 0.4899999833106996),\n",
       "   ('window', 0.0)],\n",
       "  SparseVector(1048576, {17222: 1.5404, 67697: 1.5404, 157446: 1.5404, 161112: 1.5404, 166699: 1.0296, 226815: 1.0296, 245794: 1.5404, 307547: 1.5404, 364197: 1.5404, 371597: 1.2528, 465091: 1.5404, 466911: 1.0296, 519537: 1.2528, 561197: 1.5404, 563407: 1.5404, 614062: 1.5404, 615108: 1.5404, 653886: 1.2528, 666291: 1.5404, 685591: 1.5404, 692651: 1.5404, 823871: 1.2528, 885101: 1.5404, 913443: 1.0296})),\n",
       " ([('actors', 0.0),\n",
       "   ('attention', 0.0),\n",
       "   ('audience participants', 0.0),\n",
       "   ('experience', 0.0),\n",
       "   ('experiment', 0.13999999970197674),\n",
       "   ('hell', 0.0),\n",
       "   ('one', 0.0),\n",
       "   ('orchestra pit', 0.0),\n",
       "   ('participation', 0.010000000298023226),\n",
       "   ('people', 0.0),\n",
       "   ('something', 0.0),\n",
       "   ('stage', 0.0),\n",
       "   ('story', 0.0),\n",
       "   ('theatre', 0.0),\n",
       "   ('theatre door', 0.0),\n",
       "   ('world', 0.0)],\n",
       "  SparseVector(1048576, {92801: 1.2528, 103685: 1.2528, 120399: 0.5596, 221425: 1.2528, 293798: 0.2412, 332447: 0.6931, 548146: 1.2528, 561553: 1.2528, 769269: 0.4418, 820660: 1.2528, 897134: 0.4418, 933120: 0.5596, 952124: 1.2528, 970512: 1.2528, 990261: 0.8473, 1041673: 1.2528})),\n",
       " ([('actors', 0.0),\n",
       "   ('attention', 0.0),\n",
       "   ('audience participants', 0.0),\n",
       "   ('experience', 0.0),\n",
       "   ('experiment', 0.13999999970197674),\n",
       "   ('hell', 0.0),\n",
       "   ('one', 0.0),\n",
       "   ('orchestra pit', 0.0),\n",
       "   ('participation', 0.010000000298023226),\n",
       "   ('people', 0.0),\n",
       "   ('something', 0.0),\n",
       "   ('stage', 0.0),\n",
       "   ('story', 0.0),\n",
       "   ('theatre', 0.0),\n",
       "   ('theatre door', 0.0),\n",
       "   ('world', 0.0)],\n",
       "  SparseVector(1048576, {92801: 1.2528, 103685: 1.2528, 120399: 0.5596, 221425: 1.2528, 293798: 0.2412, 332447: 0.6931, 548146: 1.2528, 561553: 1.2528, 769269: 0.4418, 820660: 1.2528, 897134: 0.4418, 933120: 0.5596, 952124: 1.2528, 970512: 1.2528, 990261: 0.8473, 1041673: 1.2528})),\n",
       " ([('actors', 0.0),\n",
       "   ('attention', 0.0),\n",
       "   ('audience participants', 0.0),\n",
       "   ('experience', 0.0),\n",
       "   ('experiment', 0.13999999970197674),\n",
       "   ('hell', 0.0),\n",
       "   ('one', 0.0),\n",
       "   ('orchestra pit', 0.0),\n",
       "   ('participation', 0.010000000298023226),\n",
       "   ('people', 0.0),\n",
       "   ('something', 0.0),\n",
       "   ('stage', 0.0),\n",
       "   ('story', 0.0),\n",
       "   ('theatre', 0.0),\n",
       "   ('theatre door', 0.0),\n",
       "   ('world', 0.0)],\n",
       "  SparseVector(1048576, {92801: 1.2528, 103685: 1.2528, 120399: 0.5596, 221425: 1.2528, 293798: 0.2412, 332447: 0.6931, 548146: 1.2528, 561553: 1.2528, 769269: 0.4418, 820660: 1.2528, 897134: 0.4418, 933120: 0.5596, 952124: 1.2528, 970512: 1.2528, 990261: 0.8473, 1041673: 1.2528})),\n",
       " ([('America.', -0.08000000238418581),\n",
       "   ('Broadway', 0.0),\n",
       "   ('Congress', 0.0),\n",
       "   ('Constitution', -0.36000002861023006),\n",
       "   ('Europe', -0.040000001192092904),\n",
       "   ('FUTZ', 0.0),\n",
       "   ('HAIR', -0.10000000149011612),\n",
       "   ('Jesus Christ Superstar', -0.040000001192092904),\n",
       "   ('New York', 0.0),\n",
       "   ('Off Off Broadway', 0.09000000715255752),\n",
       "   (\"Tom O'Horgan\", -0.08000000238418581),\n",
       "   ('acclaim', -0.010000000298023226),\n",
       "   ('animals', -0.010000000298023226),\n",
       "   ('cast', -0.040000001192092904),\n",
       "   ('conformity', -0.550000011920929),\n",
       "   ('director', -0.040000001192092904),\n",
       "   ('everyone', 0.0),\n",
       "   ('fable', 0.36000002861023006),\n",
       "   ('gay marriage', 0.0),\n",
       "   ('hate', -0.4899999833106996),\n",
       "   ('kind', -0.09000000715255752),\n",
       "   ('liberty', 0.0),\n",
       "   ('love', -0.03000000089406968),\n",
       "   ('mainstream', -0.010000000298023226),\n",
       "   ('man', -0.08000000238418581),\n",
       "   ('morality tale', -0.16000000476837162),\n",
       "   ('norms', -0.010000000298023226),\n",
       "   ('origins', 0.16000000476837162),\n",
       "   ('others', -0.010000000298023226),\n",
       "   ('piece', -0.06999999985098837),\n",
       "   ('pig', -0.040000001192092904),\n",
       "   ('production', -0.040000001192092904),\n",
       "   ('revenge', -0.010000000298023226),\n",
       "   ('sex', 0.005000000149011613),\n",
       "   ('something', -0.09000000715255752),\n",
       "   ('stage version', -0.040000001192092904),\n",
       "   ('story', -0.10000000298023226),\n",
       "   ('storytelling', -0.040000001192092904),\n",
       "   ('studio film', -0.040000001192092904),\n",
       "   ('surface', -0.040000001192092904),\n",
       "   ('theatre', -0.10000000149011612),\n",
       "   ('theatre movement', 0.040000001192092904),\n",
       "   ('violence', -0.36000002861023006),\n",
       "   ('way', 0.0),\n",
       "   ('world', 0.0),\n",
       "   ('Jane Fonda', 0.3599999958276747),\n",
       "   ('Robert De Niro', 0.3599999958276747),\n",
       "   ('Stanley & Iris', -0.6400000190734865),\n",
       "   ('ability', 0.010000000298023226),\n",
       "   ('acting', 0.6400000190734865),\n",
       "   ('anywhere', 0.0),\n",
       "   ('entertainment', 0.8099999570846563),\n",
       "   ('fan', 0.7800000023841847),\n",
       "   ('father', 0.0),\n",
       "   ('film', 0.08000000238418581),\n",
       "   ('gold', 0.0),\n",
       "   ('heart', -0.8099999570846563),\n",
       "   ('home', 0.0),\n",
       "   ('movie', 0.0),\n",
       "   ('people', 0.0),\n",
       "   ('performance', 0.8099999570846563),\n",
       "   ('role', 0.0),\n",
       "   ('scene', 0.0),\n",
       "   ('work', 0.040000001192092904)],\n",
       "  SparseVector(1048576, {11359: 0.4418, 18785: 1.0296, 26350: 1.0296, 40726: 1.0296, 46407: 1.0296, 58538: 1.0296, 116849: 1.2528, 120399: 0.5596, 121866: 1.0296, 127247: 1.0296, 161400: 1.2528, 186690: 1.0296, 197750: 1.2528, 208463: 1.0296, 233615: 1.0296, 248793: 1.0296, 258047: 1.0296, 293798: 0.2412, 308983: 1.0296, 344489: 1.0296, 378881: 1.0296, 405315: 1.0296, 474970: 1.2528, 486663: 1.0296, 495373: 1.0296, 496423: 1.0296, 500265: 1.2528, 582357: 1.0296, 590247: 1.0296, 605366: 1.0296, 605689: 1.0296, 606277: 1.0296, 638378: 1.0296, 653763: 1.0296, 670340: 1.0296, 673060: 0.8473, 711607: 1.0296, 712855: 1.0296, 766492: 0.8473, 769269: 0.4418, 782550: 1.0296, 783311: 1.0296, 788576: 1.2528, 798256: 1.2528, 811009: 1.0296, 823082: 1.2528, 838443: 1.0296, 852556: 1.0296, 866176: 1.0296, 880413: 1.2528, 881999: 1.2528, 885727: 1.0296, 897134: 0.4418, 933120: 0.5596, 933136: 1.2528, 936104: 0.8473, 961419: 1.0296, 964947: 1.0296, 966108: 1.2528, 973115: 1.0296, 1002406: 1.2528, 1003024: 1.0296, 1017085: 1.0296, 1035620: 0.8473})),\n",
       " ([('African American', 0.0),\n",
       "   ('Catch Me if You Can', 0.25),\n",
       "   ('Coplandesque Americana', 0.0),\n",
       "   ('Danny deVito', 0.0),\n",
       "   ('How Green was my Valley', 0.0),\n",
       "   ('Iris', 0.0),\n",
       "   ('John Voigt', 0.0),\n",
       "   ('John Williams', 0.0),\n",
       "   ('Konrack', 0.0),\n",
       "   ('Renaissance Man', 0.0),\n",
       "   (\"Schindler's List\", 0.0),\n",
       "   ('South Carolina', 0.0),\n",
       "   ('Stanley', 0.0),\n",
       "   ('Star Wars', 0.0),\n",
       "   ('addition', 1.7099999332427984),\n",
       "   ('anything', 0.010000000298023226),\n",
       "   ('attention', 0.0),\n",
       "   ('awakening', 0.8099999570846563),\n",
       "   ('beauty', 0.36000002861023006),\n",
       "   ('bombasticities', -0.010000000298023226),\n",
       "   ('charges', 0.0),\n",
       "   ('commentators', 0.0),\n",
       "   ('credits', 0.0),\n",
       "   ('education movies', 0.6400000190734865),\n",
       "   ('film', -0.08000000238418581),\n",
       "   ('genre', 0.0),\n",
       "   ('idea', -0.08999999895691868),\n",
       "   ('middle', 0.0),\n",
       "   ('movie', 0.32000000953674324),\n",
       "   ('name', 0.0),\n",
       "   ('none', 0.0),\n",
       "   ('one', 0.0),\n",
       "   ('opinion', 0.0),\n",
       "   ('plot', 0.8099999570846563),\n",
       "   ('reception', 0.0),\n",
       "   ('score', 0.22250001557171373),\n",
       "   ('scores', 0.0),\n",
       "   ('sensitivity', 0.36000002861023006),\n",
       "   ('side', 0.8099999570846563),\n",
       "   ('sophistication', 0.36000002861023006),\n",
       "   ('story', 0.0),\n",
       "   ('style', 0.0),\n",
       "   ('surprise', 0.8099999570846563),\n",
       "   ('tender', 0.0),\n",
       "   ('tenderness', 0.040000001192092904),\n",
       "   ('thing', 0.0),\n",
       "   ('title', 0.32000000953674324),\n",
       "   ('wit', 0.36000002861023006),\n",
       "   ('Jane Fonda', 0.0),\n",
       "   ('Martin Ritt', 0.020000000596046452),\n",
       "   ('Pat Barker', -0.040000001192092904),\n",
       "   ('Robert De Niro', 0.010000000298023226),\n",
       "   ('Union Street', -0.010000000298023226),\n",
       "   ('blue-collar fantasy', -0.120000006556511),\n",
       "   ('characters', 0.01500000044703484),\n",
       "   ('charisma', 0.0),\n",
       "   ('closet-inventor', 0.0),\n",
       "   ('cynics', 0.010000000298023226),\n",
       "   ('degree', 0.8099999570846563),\n",
       "   ('drama', 0.8099999570846563),\n",
       "   ('editing', -0.9799999666213992),\n",
       "   ('ending', 0.16000000476837162),\n",
       "   ('finale', 0.020000000596046452),\n",
       "   ('fireworks', -0.040000001192092904),\n",
       "   ('illiteracy angle', -0.020000000596046452),\n",
       "   ('issues', 0.0),\n",
       "   ('leads', -0.09000000715255752),\n",
       "   ('love story', 0.0),\n",
       "   ('moments', 0.010000000298023226),\n",
       "   ('novel', 0.0),\n",
       "   ('overtures', 0.0),\n",
       "   ('picture', 0.0),\n",
       "   ('pleasure', 0.0),\n",
       "   ('rest', 0.0),\n",
       "   ('stars', 0.0)],\n",
       "  SparseVector(1048576, {5858: 1.9459, 11359: 0.4418, 20558: 1.5404, 29101: 1.5404, 47016: 1.9459, 71823: 1.5404, 76405: 1.5404, 98036: 1.5404, 113170: 1.9459, 131231: 1.9459, 150952: 1.5404, 164212: 1.5404, 194961: 1.5404, 216552: 1.5404, 253634: 1.9459, 256132: 1.5404, 288593: 1.5404, 293798: 0.2412, 305394: 1.5404, 321193: 1.9459, 331935: 1.9459, 332447: 0.6931, 343716: 1.5404, 344489: 1.0296, 355241: 1.9459, 355781: 1.9459, 361588: 1.5404, 416688: 1.5404, 425057: 1.5404, 464826: 1.5404, 473416: 1.5404, 481091: 1.5404, 506672: 1.5404, 535768: 1.5404, 546084: 1.9459, 557168: 1.5404, 592333: 1.9459, 595112: 1.5404, 595455: 1.5404, 597390: 1.0296, 617167: 1.9459, 634922: 1.5404, 653886: 1.2528, 671791: 1.9459, 677343: 1.9459, 686355: 1.5404, 700245: 1.9459, 712355: 1.9459, 713373: 1.5404, 717960: 1.5404, 724164: 1.5404, 727056: 1.5404, 755488: 1.5404, 761597: 1.9459, 789370: 1.5404, 811276: 1.5404, 813370: 1.9459, 822881: 1.9459, 862170: 1.9459, 885727: 1.0296, 900646: 1.5404, 916404: 1.5404, 928075: 1.9459, 936104: 0.8473, 942045: 1.5404, 947304: 1.5404, 959684: 1.5404, 975113: 1.9459, 985144: 1.5404, 990261: 0.8473, 1003111: 1.5404, 1018301: 1.9459, 1025928: 1.5404, 1031172: 1.5404, 1035064: 1.5404})),\n",
       " ([('Bromwell High', 0.0),\n",
       "   ('INSPECTOR', 0.0),\n",
       "   ('STUDENT', 0.0),\n",
       "   ('Teachers', 0.0),\n",
       "   ('adults', 0.0),\n",
       "   ('age', 0.0),\n",
       "   ('all', 0.0),\n",
       "   ('episode', 0.0),\n",
       "   ('line', 0.0),\n",
       "   ('one', -0.005000000149011613),\n",
       "   ('pettiness', -0.010000000298023226),\n",
       "   ('pity', 0.0),\n",
       "   ('pomp', 0.0),\n",
       "   ('programs', 0.0),\n",
       "   ('reality', 0.0),\n",
       "   ('satire', 0.0),\n",
       "   ('school', -0.04500000357627876),\n",
       "   ('school life', 0.0),\n",
       "   ('schools', -0.040000001192092904),\n",
       "   ('scramble', -0.040000001192092904),\n",
       "   ('situation', 0.0),\n",
       "   ('student', -0.010000000298023226),\n",
       "   ('students', -0.020000000596046452),\n",
       "   ('teachers', -0.20249998927116408),\n",
       "   ('teaching profession', 0.0),\n",
       "   ('Bip', -0.03000000163912775),\n",
       "   ('Blunder', 0.010000000298023226),\n",
       "   ('Canada', 0.0),\n",
       "   ('Dead Ringers', 0.0),\n",
       "   ('Doon Mackichan', 0.010000000298023226),\n",
       "   ('EastEnders Chrissie Watts', 0.010000000298023226),\n",
       "   ('Gina Yashere', 0.0),\n",
       "   ('Keisha', 0.20000000298023224),\n",
       "   ('Latrina', -0.16000000476837162),\n",
       "   ('Lenny Henry', 0.0),\n",
       "   ('Mark Perry', 0.0),\n",
       "   ('Maths', -0.8099999570846563),\n",
       "   ('Natella', -0.25),\n",
       "   ('Nina Conti', 0.0),\n",
       "   ('Smack The Pony', 0.0),\n",
       "   ('South Park', 0.09000000715255752),\n",
       "   ('Tracy-Ann Oberman', 0.0),\n",
       "   ('adult comedy cartoons', 0.36000002861023006),\n",
       "   ('adventures', 0.0),\n",
       "   ('bitches', -0.09000000715255752),\n",
       "   ('cast', 0.8099999570846563),\n",
       "   ('format', 0.0),\n",
       "   ('others', 0.0),\n",
       "   ('principal', -0.8099999570846563),\n",
       "   ('stories', 0.0),\n",
       "   ('sweets', -0.8099999570846563),\n",
       "   ('teacher', -0.09000000715255752),\n",
       "   ('teenage girls', 0.0),\n",
       "   ('African American', 0.0),\n",
       "   ('Catch Me if You Can', 0.25),\n",
       "   ('Coplandesque Americana', 0.0),\n",
       "   ('Danny deVito', 0.0),\n",
       "   ('How Green was my Valley', 0.0),\n",
       "   ('Iris', 0.0),\n",
       "   ('John Voigt', 0.0),\n",
       "   ('John Williams', 0.0),\n",
       "   ('Konrack', 0.0),\n",
       "   ('Renaissance Man', 0.0),\n",
       "   (\"Schindler's List\", 0.0),\n",
       "   ('South Carolina', 0.0),\n",
       "   ('Stanley', 0.0),\n",
       "   ('Star Wars', 0.0),\n",
       "   ('addition', 1.7099999332427984),\n",
       "   ('anything', 0.010000000298023226),\n",
       "   ('attention', 0.0),\n",
       "   ('awakening', 0.8099999570846563),\n",
       "   ('beauty', 0.36000002861023006),\n",
       "   ('bombasticities', -0.010000000298023226),\n",
       "   ('charges', 0.0),\n",
       "   ('commentators', 0.0),\n",
       "   ('credits', 0.0),\n",
       "   ('education movies', 0.6400000190734865),\n",
       "   ('film', 0.0),\n",
       "   ('genre', 0.0),\n",
       "   ('idea', -0.08999999895691868),\n",
       "   ('middle', 0.0),\n",
       "   ('movie', 0.32000000953674324),\n",
       "   ('name', 0.0),\n",
       "   ('none', 0.0),\n",
       "   ('opinion', 0.0),\n",
       "   ('plot', 0.8099999570846563),\n",
       "   ('reception', 0.0),\n",
       "   ('score', 0.22250001557171373),\n",
       "   ('scores', 0.0),\n",
       "   ('sensitivity', 0.36000002861023006),\n",
       "   ('side', 0.8099999570846563),\n",
       "   ('sophistication', 0.36000002861023006),\n",
       "   ('story', 0.0),\n",
       "   ('style', 0.0),\n",
       "   ('surprise', 0.8099999570846563),\n",
       "   ('tender', 0.0),\n",
       "   ('tenderness', 0.040000001192092904),\n",
       "   ('thing', 0.0),\n",
       "   ('title', 0.0),\n",
       "   ('wit', 0.36000002861023006)],\n",
       "  SparseVector(1048576, {2620: 1.9459, 7450: 1.5404, 11359: 0.4418, 20558: 1.5404, 26750: 1.9459, 29101: 1.5404, 31153: 1.9459, 38682: 1.9459, 49326: 1.9459, 71823: 1.5404, 76405: 1.5404, 98036: 1.5404, 101809: 1.9459, 133280: 1.9459, 150952: 1.5404, 163162: 1.5404, 163495: 1.5404, 164212: 1.5404, 166699: 1.0296, 169927: 1.9459, 183909: 1.5404, 185232: 1.9459, 194961: 1.5404, 208700: 1.9459, 216552: 1.5404, 226815: 1.0296, 256132: 1.5404, 288593: 1.5404, 293798: 0.2412, 297455: 1.9459, 305394: 1.5404, 312254: 1.9459, 316920: 1.5404, 318433: 1.9459, 332447: 0.6931, 343716: 1.5404, 361588: 1.5404, 371597: 1.2528, 379496: 1.9459, 416688: 1.5404, 417940: 1.5404, 425057: 1.5404, 454040: 1.5404, 464826: 1.5404, 466911: 1.0296, 470993: 1.9459, 473416: 1.5404, 481091: 1.5404, 506672: 1.5404, 519537: 1.2528, 521632: 1.5404, 528239: 1.5404, 535768: 1.5404, 557168: 1.5404, 558251: 1.5404, 575648: 1.2528, 595112: 1.5404, 595455: 1.5404, 609032: 1.9459, 630369: 1.9459, 634922: 1.5404, 673060: 0.8473, 686355: 1.5404, 713373: 1.5404, 717960: 1.5404, 724164: 1.5404, 727056: 1.5404, 746389: 1.5404, 755488: 1.5404, 771102: 1.5404, 771285: 1.5404, 789370: 1.5404, 807762: 1.9459, 811276: 1.5404, 823871: 1.2528, 834250: 1.9459, 854052: 1.5404, 866668: 1.5404, 871605: 1.9459, 884448: 1.9459, 893774: 1.5404, 900646: 1.5404, 904594: 1.9459, 913443: 1.0296, 916404: 1.5404, 932690: 1.9459, 936104: 0.8473, 942045: 1.5404, 947304: 1.5404, 948201: 1.5404, 959684: 1.5404, 970314: 1.5404, 985144: 1.5404, 990261: 0.8473, 1003111: 1.5404, 1025928: 1.5404, 1031172: 1.5404, 1033719: 1.5404, 1035064: 1.5404, 1035620: 0.8473})),\n",
       " ([('America.', -0.08000000238418581),\n",
       "   ('Broadway', 0.0),\n",
       "   ('Congress', 0.0),\n",
       "   ('Constitution', -0.36000002861023006),\n",
       "   ('Europe', -0.040000001192092904),\n",
       "   ('FUTZ', 0.0),\n",
       "   ('HAIR', -0.10000000149011612),\n",
       "   ('Jesus Christ Superstar', -0.040000001192092904),\n",
       "   ('New York', 0.0),\n",
       "   ('Off Off Broadway', 0.09000000715255752),\n",
       "   (\"Tom O'Horgan\", -0.08000000238418581),\n",
       "   ('acclaim', -0.010000000298023226),\n",
       "   ('animals', -0.010000000298023226),\n",
       "   ('cast', -0.040000001192092904),\n",
       "   ('conformity', -0.550000011920929),\n",
       "   ('director', -0.040000001192092904),\n",
       "   ('everyone', 0.0),\n",
       "   ('fable', 0.36000002861023006),\n",
       "   ('gay marriage', 0.0),\n",
       "   ('hate', -0.4899999833106996),\n",
       "   ('kind', -0.09000000715255752),\n",
       "   ('liberty', 0.0),\n",
       "   ('love', -0.03000000089406968),\n",
       "   ('mainstream', -0.010000000298023226),\n",
       "   ('man', -0.08000000238418581),\n",
       "   ('morality tale', -0.16000000476837162),\n",
       "   ('norms', -0.010000000298023226),\n",
       "   ('origins', 0.16000000476837162),\n",
       "   ('others', -0.010000000298023226),\n",
       "   ('piece', -0.06999999985098837),\n",
       "   ('pig', -0.040000001192092904),\n",
       "   ('production', -0.040000001192092904),\n",
       "   ('revenge', -0.010000000298023226),\n",
       "   ('sex', 0.005000000149011613),\n",
       "   ('something', -0.09000000715255752),\n",
       "   ('stage version', -0.040000001192092904),\n",
       "   ('story', -0.10000000298023226),\n",
       "   ('storytelling', -0.040000001192092904),\n",
       "   ('studio film', -0.040000001192092904),\n",
       "   ('surface', -0.040000001192092904),\n",
       "   ('theatre', -0.10000000149011612),\n",
       "   ('theatre movement', 0.040000001192092904),\n",
       "   ('violence', -0.36000002861023006),\n",
       "   ('way', 0.0),\n",
       "   ('world', 0.0),\n",
       "   ('Jane Fonda', 0.3599999958276747),\n",
       "   ('Robert De Niro', 0.3599999958276747),\n",
       "   ('Stanley & Iris', -0.6400000190734865),\n",
       "   ('ability', 0.010000000298023226),\n",
       "   ('acting', 0.6400000190734865),\n",
       "   ('anywhere', 0.0),\n",
       "   ('entertainment', 0.8099999570846563),\n",
       "   ('fan', 0.7800000023841847),\n",
       "   ('father', 0.0),\n",
       "   ('film', 0.08000000238418581),\n",
       "   ('gold', 0.0),\n",
       "   ('heart', -0.8099999570846563),\n",
       "   ('home', 0.0),\n",
       "   ('movie', 0.0),\n",
       "   ('people', 0.0),\n",
       "   ('performance', 0.8099999570846563),\n",
       "   ('role', 0.0),\n",
       "   ('scene', 0.0),\n",
       "   ('work', 0.040000001192092904)],\n",
       "  SparseVector(1048576, {11359: 0.4418, 18785: 1.0296, 26350: 1.0296, 40726: 1.0296, 46407: 1.0296, 58538: 1.0296, 116849: 1.2528, 120399: 0.5596, 121866: 1.0296, 127247: 1.0296, 161400: 1.2528, 186690: 1.0296, 197750: 1.2528, 208463: 1.0296, 233615: 1.0296, 248793: 1.0296, 258047: 1.0296, 293798: 0.2412, 308983: 1.0296, 344489: 1.0296, 378881: 1.0296, 405315: 1.0296, 474970: 1.2528, 486663: 1.0296, 495373: 1.0296, 496423: 1.0296, 500265: 1.2528, 582357: 1.0296, 590247: 1.0296, 605366: 1.0296, 605689: 1.0296, 606277: 1.0296, 638378: 1.0296, 653763: 1.0296, 670340: 1.0296, 673060: 0.8473, 711607: 1.0296, 712855: 1.0296, 766492: 0.8473, 769269: 0.4418, 782550: 1.0296, 783311: 1.0296, 788576: 1.2528, 798256: 1.2528, 811009: 1.0296, 823082: 1.2528, 838443: 1.0296, 852556: 1.0296, 866176: 1.0296, 880413: 1.2528, 881999: 1.2528, 885727: 1.0296, 897134: 0.4418, 933120: 0.5596, 933136: 1.2528, 936104: 0.8473, 961419: 1.0296, 964947: 1.0296, 966108: 1.2528, 973115: 1.0296, 1002406: 1.2528, 1003024: 1.0296, 1017085: 1.0296, 1035620: 0.8473})),\n",
       " ([('action', 0.0),\n",
       "   ('areas', 0.0),\n",
       "   ('beer', -0.040000001192092904),\n",
       "   ('child', -1.7099999332427984),\n",
       "   ('drama', 0.7200000572204601),\n",
       "   ('film', 0.0),\n",
       "   ('jackass husband', -0.03000000163912775),\n",
       "   ('life', 0.0),\n",
       "   ('nest egg', -0.09000000715255752),\n",
       "   ('quarrels', -0.16000000476837162),\n",
       "   ('relatives', -0.18000001430511503),\n",
       "   ('school', -0.09000000715255752),\n",
       "   ('someone', 0.0),\n",
       "   ('supporter', -1.0800000143051136),\n",
       "   ('thumbs', 0.0),\n",
       "   ('viewers', 0.0),\n",
       "   ('world', -0.25)],\n",
       "  SparseVector(1048576, {11359: 0.4418, 59513: 1.9459, 73434: 1.9459, 115481: 1.2528, 217689: 1.9459, 275038: 1.9459, 325311: 1.9459, 445798: 1.9459, 575648: 1.2528, 587192: 1.9459, 597390: 1.0296, 627329: 1.9459, 855589: 1.9459, 861134: 1.9459, 896326: 1.9459, 897134: 0.4418, 954071: 1.9459})),\n",
       " ([('Bromwell High', 0.0),\n",
       "   ('INSPECTOR', 0.0),\n",
       "   ('STUDENT', 0.0),\n",
       "   ('Teachers', 0.0),\n",
       "   ('adults', 0.0),\n",
       "   ('age', 0.0),\n",
       "   ('all', 0.0),\n",
       "   ('episode', 0.0),\n",
       "   ('line', 0.0),\n",
       "   ('one', -0.010000000298023226),\n",
       "   ('pettiness', -0.010000000298023226),\n",
       "   ('pity', 0.0),\n",
       "   ('pomp', 0.0),\n",
       "   ('programs', 0.0),\n",
       "   ('reality', 0.0),\n",
       "   ('satire', 0.0),\n",
       "   ('school', -0.09000000715255752),\n",
       "   ('school life', 0.0),\n",
       "   ('schools', -0.040000001192092904),\n",
       "   ('scramble', -0.040000001192092904),\n",
       "   ('situation', 0.0),\n",
       "   ('student', -0.010000000298023226),\n",
       "   ('students', -0.020000000596046452),\n",
       "   ('teachers', -0.40499997854232817),\n",
       "   ('teaching profession', 0.0)],\n",
       "  SparseVector(1048576, {7450: 1.5404, 163162: 1.5404, 163495: 1.5404, 166699: 1.0296, 183909: 1.5404, 226815: 1.0296, 316920: 1.5404, 332447: 0.6931, 417940: 1.5404, 454040: 1.5404, 466911: 1.0296, 521632: 1.5404, 528239: 1.5404, 558251: 1.5404, 575648: 1.2528, 746389: 1.5404, 771102: 1.5404, 771285: 1.5404, 854052: 1.5404, 866668: 1.5404, 893774: 1.5404, 913443: 1.0296, 948201: 1.5404, 970314: 1.5404, 1033719: 1.5404})),\n",
       " ([('America.', -0.08000000238418581),\n",
       "   ('Broadway', 0.0),\n",
       "   ('Congress', 0.0),\n",
       "   ('Constitution', -0.36000002861023006),\n",
       "   ('Europe', -0.040000001192092904),\n",
       "   ('FUTZ', 0.0),\n",
       "   ('HAIR', -0.10000000149011612),\n",
       "   ('Jesus Christ Superstar', -0.040000001192092904),\n",
       "   ('New York', 0.0),\n",
       "   ('Off Off Broadway', 0.09000000715255752),\n",
       "   (\"Tom O'Horgan\", -0.08000000238418581),\n",
       "   ('acclaim', -0.010000000298023226),\n",
       "   ('animals', -0.010000000298023226),\n",
       "   ('cast', -0.040000001192092904),\n",
       "   ('conformity', -0.550000011920929),\n",
       "   ('director', -0.040000001192092904),\n",
       "   ('everyone', 0.0),\n",
       "   ('fable', 0.36000002861023006),\n",
       "   ('gay marriage', 0.0),\n",
       "   ('hate', -0.4899999833106996),\n",
       "   ('kind', -0.09000000715255752),\n",
       "   ('liberty', 0.0),\n",
       "   ('love', -0.03000000089406968),\n",
       "   ('mainstream', -0.010000000298023226),\n",
       "   ('man', -0.08000000238418581),\n",
       "   ('morality tale', -0.16000000476837162),\n",
       "   ('norms', -0.010000000298023226),\n",
       "   ('origins', 0.16000000476837162),\n",
       "   ('others', -0.010000000298023226),\n",
       "   ('piece', -0.06999999985098837),\n",
       "   ('pig', -0.040000001192092904),\n",
       "   ('production', -0.040000001192092904),\n",
       "   ('revenge', -0.010000000298023226),\n",
       "   ('sex', 0.005000000149011613),\n",
       "   ('something', -0.09000000715255752),\n",
       "   ('stage version', -0.040000001192092904),\n",
       "   ('story', -0.05000000149011613),\n",
       "   ('storytelling', -0.040000001192092904),\n",
       "   ('studio film', -0.040000001192092904),\n",
       "   ('surface', -0.040000001192092904),\n",
       "   ('theatre', -0.10000000149011612),\n",
       "   ('theatre movement', 0.040000001192092904),\n",
       "   ('violence', -0.36000002861023006),\n",
       "   ('way', 0.0),\n",
       "   ('world', 0.0),\n",
       "   ('De Niro', 0.010000000298023226),\n",
       "   ('Fonda', 0.010000000298023226),\n",
       "   ('acting', 0.25),\n",
       "   ('average', 0.010000000298023226),\n",
       "   ('best.', 0.0),\n",
       "   ('blue collar', 0.010000000298023226),\n",
       "   ('cinematography', 0.0),\n",
       "   ('coartship', 0.010000000298023226),\n",
       "   ('drama', 0.16000000476837162),\n",
       "   ('fans', 0.010000000298023226),\n",
       "   ('film', -0.2750000059604645),\n",
       "   ('illiteracy', 0.010000000298023226),\n",
       "   ('level.It', 0.010000000298023226),\n",
       "   ('life', 0.0),\n",
       "   ('lives', 0.040000001192092904),\n",
       "   ('love stories', 0.0),\n",
       "   ('love story movie', 0.08000000238418581),\n",
       "   ('people', 0.09249999903142449),\n",
       "   ('screenplay', 0.010000000298023226),\n",
       "   ('script', 0.010000000298023226),\n",
       "   ('subject matter', 0.010000000298023226)],\n",
       "  SparseVector(1048576, {11359: 0.4418, 18785: 1.0296, 26350: 1.0296, 40726: 1.0296, 46407: 1.0296, 58538: 1.0296, 102356: 1.5404, 115481: 1.2528, 120399: 0.5596, 121866: 1.0296, 127247: 1.0296, 186690: 1.0296, 208463: 1.0296, 227381: 1.5404, 233615: 1.0296, 248793: 1.0296, 258047: 1.0296, 280068: 1.5404, 293798: 0.2412, 296995: 1.5404, 299097: 1.5404, 308983: 1.0296, 316140: 1.5404, 378881: 1.0296, 405315: 1.0296, 486663: 1.0296, 495373: 1.0296, 496423: 1.0296, 513325: 1.5404, 531473: 1.5404, 582357: 1.0296, 590247: 1.0296, 597390: 1.0296, 605366: 1.0296, 605689: 1.0296, 606277: 1.0296, 608482: 1.5404, 613803: 1.5404, 638378: 1.0296, 647992: 1.5404, 653763: 1.0296, 670340: 1.0296, 673060: 0.8473, 696384: 1.5404, 711607: 1.0296, 712855: 1.0296, 766492: 0.8473, 769269: 0.4418, 782550: 1.0296, 783311: 1.0296, 811009: 1.0296, 838443: 1.0296, 852556: 1.0296, 866176: 1.0296, 873376: 1.5404, 889687: 1.5404, 897134: 0.4418, 915917: 1.5404, 933120: 0.5596, 940202: 1.5404, 961419: 1.0296, 964947: 1.0296, 973115: 1.0296, 1003024: 1.0296, 1017085: 1.0296, 1035620: 0.8473})),\n",
       " ([('America.', -0.08000000238418581),\n",
       "   ('Broadway', 0.0),\n",
       "   ('Congress', 0.0),\n",
       "   ('Constitution', -0.36000002861023006),\n",
       "   ('Europe', -0.040000001192092904),\n",
       "   ('FUTZ', 0.0),\n",
       "   ('HAIR', -0.10000000149011612),\n",
       "   ('Jesus Christ Superstar', -0.040000001192092904),\n",
       "   ('New York', 0.0),\n",
       "   ('Off Off Broadway', 0.09000000715255752),\n",
       "   (\"Tom O'Horgan\", -0.08000000238418581),\n",
       "   ('acclaim', -0.010000000298023226),\n",
       "   ('animals', -0.010000000298023226),\n",
       "   ('cast', -0.040000001192092904),\n",
       "   ('conformity', -0.550000011920929),\n",
       "   ('director', -0.040000001192092904),\n",
       "   ('everyone', 0.0),\n",
       "   ('fable', 0.36000002861023006),\n",
       "   ('gay marriage', 0.0),\n",
       "   ('hate', -0.4899999833106996),\n",
       "   ('kind', -0.09000000715255752),\n",
       "   ('liberty', 0.0),\n",
       "   ('love', -0.03000000089406968),\n",
       "   ('mainstream', -0.010000000298023226),\n",
       "   ('man', -0.08000000238418581),\n",
       "   ('morality tale', -0.16000000476837162),\n",
       "   ('norms', -0.010000000298023226),\n",
       "   ('origins', 0.16000000476837162),\n",
       "   ('others', -0.010000000298023226),\n",
       "   ('piece', -0.06999999985098837),\n",
       "   ('pig', -0.040000001192092904),\n",
       "   ('production', -0.040000001192092904),\n",
       "   ('revenge', -0.010000000298023226),\n",
       "   ('sex', 0.005000000149011613),\n",
       "   ('something', -0.09000000715255752),\n",
       "   ('stage version', -0.040000001192092904),\n",
       "   ('story', -0.10000000298023226),\n",
       "   ('storytelling', -0.040000001192092904),\n",
       "   ('studio film', -0.040000001192092904),\n",
       "   ('surface', -0.040000001192092904),\n",
       "   ('theatre', -0.10000000149011612),\n",
       "   ('theatre movement', 0.040000001192092904),\n",
       "   ('violence', -0.36000002861023006),\n",
       "   ('way', 0.0),\n",
       "   ('world', 0.0),\n",
       "   ('Jane Fonda', 0.3599999958276747),\n",
       "   ('Robert De Niro', 0.3599999958276747),\n",
       "   ('Stanley & Iris', -0.6400000190734865),\n",
       "   ('ability', 0.010000000298023226),\n",
       "   ('acting', 0.6400000190734865),\n",
       "   ('anywhere', 0.0),\n",
       "   ('entertainment', 0.8099999570846563),\n",
       "   ('fan', 0.7800000023841847),\n",
       "   ('father', 0.0),\n",
       "   ('film', 0.08000000238418581),\n",
       "   ('gold', 0.0),\n",
       "   ('heart', -0.8099999570846563),\n",
       "   ('home', 0.0),\n",
       "   ('movie', 0.0),\n",
       "   ('people', 0.0),\n",
       "   ('performance', 0.8099999570846563),\n",
       "   ('role', 0.0),\n",
       "   ('scene', 0.0),\n",
       "   ('work', 0.040000001192092904)],\n",
       "  SparseVector(1048576, {11359: 0.4418, 18785: 1.0296, 26350: 1.0296, 40726: 1.0296, 46407: 1.0296, 58538: 1.0296, 116849: 1.2528, 120399: 0.5596, 121866: 1.0296, 127247: 1.0296, 161400: 1.2528, 186690: 1.0296, 197750: 1.2528, 208463: 1.0296, 233615: 1.0296, 248793: 1.0296, 258047: 1.0296, 293798: 0.2412, 308983: 1.0296, 344489: 1.0296, 378881: 1.0296, 405315: 1.0296, 474970: 1.2528, 486663: 1.0296, 495373: 1.0296, 496423: 1.0296, 500265: 1.2528, 582357: 1.0296, 590247: 1.0296, 605366: 1.0296, 605689: 1.0296, 606277: 1.0296, 638378: 1.0296, 653763: 1.0296, 670340: 1.0296, 673060: 0.8473, 711607: 1.0296, 712855: 1.0296, 766492: 0.8473, 769269: 0.4418, 782550: 1.0296, 783311: 1.0296, 788576: 1.2528, 798256: 1.2528, 811009: 1.0296, 823082: 1.2528, 838443: 1.0296, 852556: 1.0296, 866176: 1.0296, 880413: 1.2528, 881999: 1.2528, 885727: 1.0296, 897134: 0.4418, 933120: 0.5596, 933136: 1.2528, 936104: 0.8473, 961419: 1.0296, 964947: 1.0296, 966108: 1.2528, 973115: 1.0296, 1002406: 1.2528, 1003024: 1.0296, 1017085: 1.0296, 1035620: 0.8473}))]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_words_tfidf = grouped_entities.values().zip(tfidf)\n",
    "\n",
    "grouped_words_tfidf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Document  1 :\n",
      "British(1.540445040947149) Bromwell High(1.0296194171811581) Keisha(1.252762968495368) Latrina(1.252762968495368) Natella(1.252762968495368) South London Public School(1.540445040947149) characters(1.252762968495368) correctness(1.540445040947149) cross section(1.540445040947149) episode(1.0296194171811581) escapades(1.540445040947149) fun(1.540445040947149) laughter(1.540445040947149) parody(1.540445040947149) protagonists(1.540445040947149) show(1.540445040947149) shows(1.540445040947149) society(1.540445040947149) students(1.0296194171811581) subject(1.540445040947149) teachers(1.0296194171811581) term(1.540445040947149) want(1.540445040947149) window(1.540445040947149) De Niro(1.540445040947149) Fonda(1.540445040947149) acting(0.8472978603872037) average(1.540445040947149) best.(1.540445040947149) blue collar(1.540445040947149) cinematography(1.540445040947149) coartship(1.540445040947149) drama(1.0296194171811581) fans(1.540445040947149) film(0.44183275227903923) illiteracy(1.540445040947149) level.It(1.540445040947149) life(1.252762968495368) lives(1.540445040947149) love stories(1.540445040947149) love story movie(1.540445040947149) people(0.44183275227903923) screenplay(1.540445040947149) script(1.540445040947149) story(0.24116205681688804) subject matter(1.540445040947149)  \n",
      "Document  2 :\n",
      "British(1.540445040947149) Bromwell High(1.0296194171811581) Keisha(1.252762968495368) Latrina(1.252762968495368) Natella(1.252762968495368) South London Public School(1.540445040947149) characters(1.252762968495368) correctness(1.540445040947149) cross section(1.540445040947149) episode(1.0296194171811581) escapades(1.540445040947149) fun(1.540445040947149) laughter(1.540445040947149) parody(1.540445040947149) protagonists(1.540445040947149) show(1.540445040947149) shows(1.540445040947149) society(1.540445040947149) students(1.0296194171811581) subject(1.540445040947149) teachers(1.0296194171811581) term(1.540445040947149) want(1.540445040947149) window(1.540445040947149)  \n",
      "Document  3 :\n",
      "actors(1.252762968495368) attention(0.8472978603872037) audience participants(1.252762968495368) experience(1.252762968495368) experiment(1.252762968495368) hell(1.252762968495368) one(0.6931471805599453) orchestra pit(1.252762968495368) participation(1.252762968495368) people(0.44183275227903923) something(0.5596157879354227) stage(1.252762968495368) story(0.24116205681688804) theatre(0.5596157879354227) theatre door(1.252762968495368) world(0.44183275227903923)  \n",
      "Document  4 :\n",
      "actors(1.252762968495368) attention(0.8472978603872037) audience participants(1.252762968495368) experience(1.252762968495368) experiment(1.252762968495368) hell(1.252762968495368) one(0.6931471805599453) orchestra pit(1.252762968495368) participation(1.252762968495368) people(0.44183275227903923) something(0.5596157879354227) stage(1.252762968495368) story(0.24116205681688804) theatre(0.5596157879354227) theatre door(1.252762968495368) world(0.44183275227903923)  \n",
      "Document  5 :\n",
      "actors(1.252762968495368) attention(0.8472978603872037) audience participants(1.252762968495368) experience(1.252762968495368) experiment(1.252762968495368) hell(1.252762968495368) one(0.6931471805599453) orchestra pit(1.252762968495368) participation(1.252762968495368) people(0.44183275227903923) something(0.5596157879354227) stage(1.252762968495368) story(0.24116205681688804) theatre(0.5596157879354227) theatre door(1.252762968495368) world(0.44183275227903923)  \n",
      "Document  6 :\n",
      "America.(1.0296194171811581) Broadway(1.0296194171811581) Congress(1.0296194171811581) Constitution(1.0296194171811581) Europe(1.0296194171811581) FUTZ(1.0296194171811581) HAIR(1.0296194171811581) Jesus Christ Superstar(1.0296194171811581) New York(1.0296194171811581) Off Off Broadway(1.0296194171811581) Tom O'Horgan(1.0296194171811581) acclaim(1.0296194171811581) animals(1.0296194171811581) cast(0.8472978603872037) conformity(1.0296194171811581) director(1.0296194171811581) everyone(1.0296194171811581) fable(1.0296194171811581) gay marriage(1.0296194171811581) hate(1.0296194171811581) kind(1.0296194171811581) liberty(1.0296194171811581) love(1.0296194171811581) mainstream(1.0296194171811581) man(1.0296194171811581) morality tale(1.0296194171811581) norms(1.0296194171811581) origins(1.0296194171811581) others(0.8472978603872037) piece(1.0296194171811581) pig(1.0296194171811581) production(1.0296194171811581) revenge(1.0296194171811581) sex(1.0296194171811581) something(0.5596157879354227) stage version(1.0296194171811581) story(0.24116205681688804) storytelling(1.0296194171811581) studio film(1.0296194171811581) surface(1.0296194171811581) theatre(0.5596157879354227) theatre movement(1.0296194171811581) violence(1.0296194171811581) way(1.0296194171811581) world(0.44183275227903923) Jane Fonda(1.0296194171811581) Robert De Niro(1.0296194171811581) Stanley & Iris(1.252762968495368) ability(1.252762968495368) acting(0.8472978603872037) anywhere(1.252762968495368) entertainment(1.252762968495368) fan(1.252762968495368) father(1.252762968495368) film(0.44183275227903923) gold(1.252762968495368) heart(1.252762968495368) home(1.252762968495368) movie(0.8472978603872037) people(0.44183275227903923) performance(1.252762968495368) role(1.252762968495368) scene(1.252762968495368) work(1.252762968495368)  \n",
      "Document  7 :\n",
      "African American(1.540445040947149) Catch Me if You Can(1.540445040947149) Coplandesque Americana(1.540445040947149) Danny deVito(1.540445040947149) How Green was my Valley(1.540445040947149) Iris(1.540445040947149) John Voigt(1.540445040947149) John Williams(1.540445040947149) Konrack(1.540445040947149) Renaissance Man(1.540445040947149) Schindler's List(1.540445040947149) South Carolina(1.540445040947149) Stanley(1.540445040947149) Star Wars(1.540445040947149) addition(1.540445040947149) anything(1.540445040947149) attention(0.8472978603872037) awakening(1.540445040947149) beauty(1.540445040947149) bombasticities(1.540445040947149) charges(1.540445040947149) commentators(1.540445040947149) credits(1.540445040947149) education movies(1.540445040947149) film(0.44183275227903923) genre(1.540445040947149) idea(1.540445040947149) middle(1.540445040947149) movie(0.8472978603872037) name(1.540445040947149) none(1.540445040947149) one(0.6931471805599453) opinion(1.540445040947149) plot(1.540445040947149) reception(1.540445040947149) score(1.540445040947149) scores(1.540445040947149) sensitivity(1.540445040947149) side(1.540445040947149) sophistication(1.540445040947149) story(0.24116205681688804) style(1.540445040947149) surprise(1.540445040947149) tender(1.540445040947149) tenderness(1.540445040947149) thing(1.540445040947149) title(1.540445040947149) wit(1.540445040947149) Jane Fonda(1.0296194171811581) Martin Ritt(1.9459101490553132) Pat Barker(1.9459101490553132) Robert De Niro(1.0296194171811581) Union Street(1.9459101490553132) blue-collar fantasy(1.9459101490553132) characters(1.252762968495368) charisma(1.9459101490553132) closet-inventor(1.9459101490553132) cynics(1.9459101490553132) degree(1.9459101490553132) drama(1.0296194171811581) editing(1.9459101490553132) ending(1.9459101490553132) finale(1.9459101490553132) fireworks(1.9459101490553132) illiteracy angle(1.9459101490553132) issues(1.9459101490553132) leads(1.9459101490553132) love story(1.9459101490553132) moments(1.9459101490553132) novel(1.9459101490553132) overtures(1.9459101490553132) picture(1.9459101490553132) pleasure(1.9459101490553132) rest(1.9459101490553132) stars(1.9459101490553132)  \n",
      "Document  8 :\n",
      "Bromwell High(1.0296194171811581) INSPECTOR(1.540445040947149) STUDENT(1.540445040947149) Teachers(1.540445040947149) adults(1.540445040947149) age(1.540445040947149) all(1.540445040947149) episode(1.0296194171811581) line(1.540445040947149) one(0.6931471805599453) pettiness(1.540445040947149) pity(1.540445040947149) pomp(1.540445040947149) programs(1.540445040947149) reality(1.540445040947149) satire(1.540445040947149) school(1.252762968495368) school life(1.540445040947149) schools(1.540445040947149) scramble(1.540445040947149) situation(1.540445040947149) student(1.540445040947149) students(1.0296194171811581) teachers(1.0296194171811581) teaching profession(1.540445040947149) Bip(1.9459101490553132) Blunder(1.9459101490553132) Canada(1.9459101490553132) Dead Ringers(1.9459101490553132) Doon Mackichan(1.9459101490553132) EastEnders Chrissie Watts(1.9459101490553132) Gina Yashere(1.9459101490553132) Keisha(1.252762968495368) Latrina(1.252762968495368) Lenny Henry(1.9459101490553132) Mark Perry(1.9459101490553132) Maths(1.9459101490553132) Natella(1.252762968495368) Nina Conti(1.9459101490553132) Smack The Pony(1.9459101490553132) South Park(1.9459101490553132) Tracy-Ann Oberman(1.9459101490553132) adult comedy cartoons(1.9459101490553132) adventures(1.9459101490553132) bitches(1.9459101490553132) cast(0.8472978603872037) format(1.9459101490553132) others(0.8472978603872037) principal(1.9459101490553132) stories(1.9459101490553132) sweets(1.9459101490553132) teacher(1.9459101490553132) teenage girls(1.9459101490553132) African American(1.540445040947149) Catch Me if You Can(1.540445040947149) Coplandesque Americana(1.540445040947149) Danny deVito(1.540445040947149) How Green was my Valley(1.540445040947149) Iris(1.540445040947149) John Voigt(1.540445040947149) John Williams(1.540445040947149) Konrack(1.540445040947149) Renaissance Man(1.540445040947149) Schindler's List(1.540445040947149) South Carolina(1.540445040947149) Stanley(1.540445040947149) Star Wars(1.540445040947149) addition(1.540445040947149) anything(1.540445040947149) attention(0.8472978603872037) awakening(1.540445040947149) beauty(1.540445040947149) bombasticities(1.540445040947149) charges(1.540445040947149) commentators(1.540445040947149) credits(1.540445040947149) education movies(1.540445040947149) film(0.44183275227903923) genre(1.540445040947149) idea(1.540445040947149) middle(1.540445040947149) movie(0.8472978603872037) name(1.540445040947149) none(1.540445040947149) opinion(1.540445040947149) plot(1.540445040947149) reception(1.540445040947149) score(1.540445040947149) scores(1.540445040947149) sensitivity(1.540445040947149) side(1.540445040947149) sophistication(1.540445040947149) story(0.24116205681688804) style(1.540445040947149) surprise(1.540445040947149) tender(1.540445040947149) tenderness(1.540445040947149) thing(1.540445040947149) title(1.540445040947149) wit(1.540445040947149)  \n",
      "Document  9 :\n",
      "America.(1.0296194171811581) Broadway(1.0296194171811581) Congress(1.0296194171811581) Constitution(1.0296194171811581) Europe(1.0296194171811581) FUTZ(1.0296194171811581) HAIR(1.0296194171811581) Jesus Christ Superstar(1.0296194171811581) New York(1.0296194171811581) Off Off Broadway(1.0296194171811581) Tom O'Horgan(1.0296194171811581) acclaim(1.0296194171811581) animals(1.0296194171811581) cast(0.8472978603872037) conformity(1.0296194171811581) director(1.0296194171811581) everyone(1.0296194171811581) fable(1.0296194171811581) gay marriage(1.0296194171811581) hate(1.0296194171811581) kind(1.0296194171811581) liberty(1.0296194171811581) love(1.0296194171811581) mainstream(1.0296194171811581) man(1.0296194171811581) morality tale(1.0296194171811581) norms(1.0296194171811581) origins(1.0296194171811581) others(0.8472978603872037) piece(1.0296194171811581) pig(1.0296194171811581) production(1.0296194171811581) revenge(1.0296194171811581) sex(1.0296194171811581) something(0.5596157879354227) stage version(1.0296194171811581) story(0.24116205681688804) storytelling(1.0296194171811581) studio film(1.0296194171811581) surface(1.0296194171811581) theatre(0.5596157879354227) theatre movement(1.0296194171811581) violence(1.0296194171811581) way(1.0296194171811581) world(0.44183275227903923) Jane Fonda(1.0296194171811581) Robert De Niro(1.0296194171811581) Stanley & Iris(1.252762968495368) ability(1.252762968495368) acting(0.8472978603872037) anywhere(1.252762968495368) entertainment(1.252762968495368) fan(1.252762968495368) father(1.252762968495368) film(0.44183275227903923) gold(1.252762968495368) heart(1.252762968495368) home(1.252762968495368) movie(0.8472978603872037) people(0.44183275227903923) performance(1.252762968495368) role(1.252762968495368) scene(1.252762968495368) work(1.252762968495368)  \n",
      "Document  10 :\n",
      "action(1.9459101490553132) areas(1.9459101490553132) beer(1.9459101490553132) child(1.9459101490553132) drama(1.0296194171811581) film(0.44183275227903923) jackass husband(1.9459101490553132) life(1.252762968495368) nest egg(1.9459101490553132) quarrels(1.9459101490553132) relatives(1.9459101490553132) school(1.252762968495368) someone(1.9459101490553132) supporter(1.9459101490553132) thumbs(1.9459101490553132) viewers(1.9459101490553132) world(0.44183275227903923)  \n",
      "Document  11 :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromwell High(1.0296194171811581) INSPECTOR(1.540445040947149) STUDENT(1.540445040947149) Teachers(1.540445040947149) adults(1.540445040947149) age(1.540445040947149) all(1.540445040947149) episode(1.0296194171811581) line(1.540445040947149) one(0.6931471805599453) pettiness(1.540445040947149) pity(1.540445040947149) pomp(1.540445040947149) programs(1.540445040947149) reality(1.540445040947149) satire(1.540445040947149) school(1.252762968495368) school life(1.540445040947149) schools(1.540445040947149) scramble(1.540445040947149) situation(1.540445040947149) student(1.540445040947149) students(1.0296194171811581) teachers(1.0296194171811581) teaching profession(1.540445040947149)  \n",
      "Document  12 :\n",
      "America.(1.0296194171811581) Broadway(1.0296194171811581) Congress(1.0296194171811581) Constitution(1.0296194171811581) Europe(1.0296194171811581) FUTZ(1.0296194171811581) HAIR(1.0296194171811581) Jesus Christ Superstar(1.0296194171811581) New York(1.0296194171811581) Off Off Broadway(1.0296194171811581) Tom O'Horgan(1.0296194171811581) acclaim(1.0296194171811581) animals(1.0296194171811581) cast(0.8472978603872037) conformity(1.0296194171811581) director(1.0296194171811581) everyone(1.0296194171811581) fable(1.0296194171811581) gay marriage(1.0296194171811581) hate(1.0296194171811581) kind(1.0296194171811581) liberty(1.0296194171811581) love(1.0296194171811581) mainstream(1.0296194171811581) man(1.0296194171811581) morality tale(1.0296194171811581) norms(1.0296194171811581) origins(1.0296194171811581) others(0.8472978603872037) piece(1.0296194171811581) pig(1.0296194171811581) production(1.0296194171811581) revenge(1.0296194171811581) sex(1.0296194171811581) something(0.5596157879354227) stage version(1.0296194171811581) story(0.24116205681688804) storytelling(1.0296194171811581) studio film(1.0296194171811581) surface(1.0296194171811581) theatre(0.5596157879354227) theatre movement(1.0296194171811581) violence(1.0296194171811581) way(1.0296194171811581) world(0.44183275227903923) De Niro(1.540445040947149) Fonda(1.540445040947149) acting(0.8472978603872037) average(1.540445040947149) best.(1.540445040947149) blue collar(1.540445040947149) cinematography(1.540445040947149) coartship(1.540445040947149) drama(1.0296194171811581) fans(1.540445040947149) film(0.44183275227903923) illiteracy(1.540445040947149) level.It(1.540445040947149) life(1.252762968495368) lives(1.540445040947149) love stories(1.540445040947149) love story movie(1.540445040947149) people(0.44183275227903923) screenplay(1.540445040947149) script(1.540445040947149) subject matter(1.540445040947149)  \n",
      "Document  13 :\n",
      "America.(1.0296194171811581) Broadway(1.0296194171811581) Congress(1.0296194171811581) Constitution(1.0296194171811581) Europe(1.0296194171811581) FUTZ(1.0296194171811581) HAIR(1.0296194171811581) Jesus Christ Superstar(1.0296194171811581) New York(1.0296194171811581) Off Off Broadway(1.0296194171811581) Tom O'Horgan(1.0296194171811581) acclaim(1.0296194171811581) animals(1.0296194171811581) cast(0.8472978603872037) conformity(1.0296194171811581) director(1.0296194171811581) everyone(1.0296194171811581) fable(1.0296194171811581) gay marriage(1.0296194171811581) hate(1.0296194171811581) kind(1.0296194171811581) liberty(1.0296194171811581) love(1.0296194171811581) mainstream(1.0296194171811581) man(1.0296194171811581) morality tale(1.0296194171811581) norms(1.0296194171811581) origins(1.0296194171811581) others(0.8472978603872037) piece(1.0296194171811581) pig(1.0296194171811581) production(1.0296194171811581) revenge(1.0296194171811581) sex(1.0296194171811581) something(0.5596157879354227) stage version(1.0296194171811581) story(0.24116205681688804) storytelling(1.0296194171811581) studio film(1.0296194171811581) surface(1.0296194171811581) theatre(0.5596157879354227) theatre movement(1.0296194171811581) violence(1.0296194171811581) way(1.0296194171811581) world(0.44183275227903923) Jane Fonda(1.0296194171811581) Robert De Niro(1.0296194171811581) Stanley & Iris(1.252762968495368) ability(1.252762968495368) acting(0.8472978603872037) anywhere(1.252762968495368) entertainment(1.252762968495368) fan(1.252762968495368) father(1.252762968495368) film(0.44183275227903923) gold(1.252762968495368) heart(1.252762968495368) home(1.252762968495368) movie(0.8472978603872037) people(0.44183275227903923) performance(1.252762968495368) role(1.252762968495368) scene(1.252762968495368) work(1.252762968495368)  \n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "collectedTFDF = tfidf.collect()\n",
    "print(len(collectedTFDF))\n",
    "i=1\n",
    "for d in grouped_entity_words.collect():\n",
    "    print(\"Document \", i, \":\")\n",
    "    \n",
    "    tfidfscores = [collectedTFDF[i-1][hashingTF.indexOf(d[e])] for e in range(0, len(d))]\n",
    "    \n",
    "    for e in range(0, len(d)):\n",
    "        print(d[e]+\"(\"+str(collectedTFDF[i-1][hashingTF.indexOf(d[e])])+\") \", end=\"\")\n",
    "        \n",
    "    i+=1\n",
    "    print(\" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "1                    [Animation, Comedy]\n",
      "2                               [Comedy]\n",
      "3                       [Drama, Romance]\n",
      "4             [Fantasy, Musical, Family]\n",
      "5     [Crime, Horror, Mystery, Thriller]\n",
      "6                        [Comedy, Short]\n",
      "7                         [Crime, Drama]\n",
      "8            [Horror, Mystery, Thriller]\n",
      "9                                     []\n",
      "10                               [Short]\n",
      "Name: GENRE_t, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import base64\n",
    "\n",
    "def decodeGenre(x):\n",
    "    try: \n",
    "        return pickle.loads(base64.b64decode(x[2:-1]), encoding=\"bytes\") \n",
    "        \n",
    "    except:\n",
    "        return []    \n",
    "        \n",
    "        \n",
    "genres = pd.read_csv(\"id_pos_genre_train.csv\", sep=\"\\t\", index_col=0, usecols=[1, 2, 3])\n",
    "genres = genres.fillna(value=\"b''\")\n",
    "genres[\"GENRE_t\"] = genres[\"GENRE\"].apply(decodeGenre) \n",
    "print(genres[\"GENRE_t\"])\n",
    "\n",
    "# url_df = pd.read_csv(\"id_pos_genre_train_prot2_stringdump.csv\", delimiter=\"\\t\")\n",
    "# #temp = url_df[\"GENRE\"].apply(lambda x: print(x))#pickle.loads(x.encode()))#\n",
    "# print(pickle.loads(url_df.iloc[0,3][2:-1].encode(\"utf-8\")))\n",
    "#f = open(\"id_pos_genre_train.csv\", mode=\"rb\")\n",
    "\n",
    "#o=pickle.load(f)\n",
    "\n",
    "#f.close()\n",
    "\n",
    "#print(len(o))\n",
    "#print(o)\n",
    "\n",
    "#print(o.loc[o[\"ID\"]==\"0453418\"])\n",
    "##print(o[\"ID\"]==\"0453418\")\n",
    "#print([\"Comedy\" in l for l in o[\"GENRE\"]])\n",
    "#o.loc[[\"Comedy\" in l for l in o[\"GENRE\"]]]\n",
    "\n",
    "# pickle.dumps(o.iloc[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>GENRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>453418</td>\n",
       "      <td>b'\\x80\\x02]q\\x00(X\\t\\x00\\x00\\x00Animationq\\x01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64354</td>\n",
       "      <td>b'\\x80\\x02]q\\x00X\\x06\\x00\\x00\\x00Comedyq\\x01a.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>100680</td>\n",
       "      <td>b'\\x80\\x02]q\\x00(X\\x05\\x00\\x00\\x00Dramaq\\x01X\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>177606</td>\n",
       "      <td>b'\\x80\\x02]q\\x00(X\\x07\\x00\\x00\\x00Fantasyq\\x01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>74223</td>\n",
       "      <td>b'\\x80\\x02]q\\x00(X\\x05\\x00\\x00\\x00Crimeq\\x01X\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index      ID  \\\n",
       "0           0      1  453418   \n",
       "1           1      2   64354   \n",
       "2           2      3  100680   \n",
       "3           3      4  177606   \n",
       "4           4      5   74223   \n",
       "\n",
       "                                               GENRE  \n",
       "0  b'\\x80\\x02]q\\x00(X\\t\\x00\\x00\\x00Animationq\\x01...  \n",
       "1    b'\\x80\\x02]q\\x00X\\x06\\x00\\x00\\x00Comedyq\\x01a.'  \n",
       "2  b'\\x80\\x02]q\\x00(X\\x05\\x00\\x00\\x00Dramaq\\x01X\\...  \n",
       "3  b'\\x80\\x02]q\\x00(X\\x07\\x00\\x00\\x00Fantasyq\\x01...  \n",
       "4  b'\\x80\\x02]q\\x00(X\\x05\\x00\\x00\\x00Crimeq\\x01X\\...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pickle.dumps(o.iloc[0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('a', 4), ('b', 2), ('c', 3), ('c', 6)]\n",
      "{'a': 1}\n",
      "{'a': 2.5}\n",
      "{'a': 2.5, 'b': 2}\n",
      "{'a': 2.5, 'b': 2, 'c': 3}\n",
      "[('a', 2.5), ('b', 2), ('c', 4.5)]\n"
     ]
    }
   ],
   "source": [
    "test = [(\"a\", 1), (\"b\", 2), (\"c\", 3), (\"a\", 4), (\"c\", 6)]\n",
    "\n",
    "test_sorted = sorted(test, key=lambda x: x[0])\n",
    "print(test_sorted)\n",
    "\n",
    "print(reduce(collectEntities, test_sorted))\n",
    "#entity_documents_info.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
